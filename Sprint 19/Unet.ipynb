{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Student Name: Huynh Truong Tu\n",
        " Below is my assignment for Sprint19's \"Unet\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ewQkArwDkgHY"
      },
      "source": [
        "## Problem 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "colab_type": "code",
        "id": "kpY6d7Ahmfvu",
        "outputId": "8f3363e4-42c5-45e7-8785-6beff44007ad"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/zhixuhao/unet.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "y9Zw9N6smoYQ",
        "outputId": "7a67ff22-bf92-4f59-c76a-e5d04c9518b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Volume in drive D is DATA\n",
            " Volume Serial Number is 3CD2-C2B6\n",
            "\n",
            " Directory of d:\\Py4Me\\Tscripts\\Diver\\diveintocode-ml\\Sprint 19\n",
            "\n",
            "11/16/2021  02:13 PM    <DIR>          .\n",
            "11/16/2021  02:13 PM    <DIR>          ..\n",
            "11/15/2021  05:21 PM    <DIR>          .vscode\n",
            "12/11/2019  04:05 AM       227,132,081 competition_data.zip\n",
            "12/11/2019  04:05 AM           329,525 depths.csv\n",
            "12/11/2019  04:05 AM        43,373,216 flamingo.zip\n",
            "11/15/2021  05:28 PM                65 kaggle.json\n",
            "12/11/2019  04:05 AM           270,012 sample_submission.csv\n",
            "11/16/2021  12:58 PM            58,362 Sprint_19.ipynb\n",
            "11/16/2021  10:50 AM    <DIR>          test data\n",
            "12/11/2019  04:05 AM       171,262,199 test.zip\n",
            "11/16/2021  10:47 AM       466,124,588 tgs-salt-identification-challenge.zip\n",
            "11/16/2021  10:50 AM    <DIR>          train data\n",
            "12/11/2019  04:06 AM           943,702 train.csv\n",
            "12/11/2019  04:06 AM        39,757,560 train.zip\n",
            "11/16/2021  01:48 PM    <DIR>          unet\n",
            "              10 File(s)    949,251,310 bytes\n",
            "               6 Dir(s)  628,483,624,960 bytes free\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "b0vW_aoEmqgk",
        "outputId": "6b32a76a-370e-4117-8d48-226d11ede6e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d:\\Py4Me\\Tscripts\\Diver\\diveintocode-ml\\Sprint 19\\unet\n"
          ]
        }
      ],
      "source": [
        "cd unet/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "colab_type": "code",
        "id": "IA5PvpnTmtDj",
        "outputId": "669cde34-b72e-45b5-bc72-e5a706bacb23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 30 images belonging to 1 classes.\n",
            "Found 30 images belonging to 1 classes.\n",
            "\n",
            "  1/300 [..............................] - ETA: 36:00 - loss: 0.6813 - accuracy: 0.7161\n",
            "  2/300 [..............................] - ETA: 2:08 - loss: 0.6498 - accuracy: 0.7593 \n",
            "  3/300 [..............................] - ETA: 2:08 - loss: 0.6082 - accuracy: 0.7700\n",
            "  4/300 [..............................] - ETA: 2:08 - loss: 0.6062 - accuracy: 0.7682\n",
            "  5/300 [..............................] - ETA: 2:07 - loss: 0.5919 - accuracy: 0.7715\n",
            "  6/300 [..............................] - ETA: 2:07 - loss: 0.5886 - accuracy: 0.7682\n",
            "  7/300 [..............................] - ETA: 2:06 - loss: 0.5862 - accuracy: 0.7651\n",
            "  8/300 [..............................] - ETA: 2:06 - loss: 0.5758 - accuracy: 0.7703\n",
            "  9/300 [..............................] - ETA: 2:06 - loss: 0.5705 - accuracy: 0.7722\n",
            " 10/300 [>.............................] - ETA: 2:05 - loss: 0.5683 - accuracy: 0.7714\n",
            " 11/300 [>.............................] - ETA: 2:05 - loss: 0.5636 - accuracy: 0.7732\n",
            " 12/300 [>.............................] - ETA: 2:04 - loss: 0.5598 - accuracy: 0.7749\n",
            " 13/300 [>.............................] - ETA: 2:04 - loss: 0.5578 - accuracy: 0.7749"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-16 14:14:00.588075: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-11-16 14:14:01.017646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2779 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
            "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "main.py:18: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(myGene,steps_per_epoch=300,epochs=1,callbacks=[model_checkpoint])\n",
            "2021-11-16 14:14:02.817692: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8202\n",
            "2021-11-16 14:14:04.714960: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
            "2021-11-16 14:14:04.783991: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
            "2021-11-16 14:14:06.358417: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
            "2021-11-16 14:14:07.972727: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
            "2021-11-16 14:14:08.080827: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
            "2021-11-16 14:14:08.264218: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
            "main.py:21: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  results = model.predict_generator(testGene,30,verbose=1)\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " 14/300 [>.............................] - ETA: 2:03 - loss: 0.5560 - accuracy: 0.7748\n",
            " 15/300 [>.............................] - ETA: 2:03 - loss: 0.5529 - accuracy: 0.7758\n",
            " 16/300 [>.............................] - ETA: 2:03 - loss: 0.5483 - accuracy: 0.7779\n",
            " 17/300 [>.............................] - ETA: 2:02 - loss: 0.5470 - accuracy: 0.7777\n",
            " 18/300 [>.............................] - ETA: 2:02 - loss: 0.5445 - accuracy: 0.7784\n",
            " 19/300 [>.............................] - ETA: 2:01 - loss: 0.5414 - accuracy: 0.7796\n",
            " 20/300 [=>............................] - ETA: 2:01 - loss: 0.5409 - accuracy: 0.7788\n",
            " 21/300 [=>............................] - ETA: 2:01 - loss: 0.5390 - accuracy: 0.7792\n",
            " 22/300 [=>............................] - ETA: 2:00 - loss: 0.5387 - accuracy: 0.7785\n",
            " 23/300 [=>............................] - ETA: 2:00 - loss: 0.5366 - accuracy: 0.7793\n",
            " 24/300 [=>............................] - ETA: 1:59 - loss: 0.5354 - accuracy: 0.7793\n",
            " 25/300 [=>............................] - ETA: 1:59 - loss: 0.5342 - accuracy: 0.7794\n",
            " 26/300 [=>............................] - ETA: 1:58 - loss: 0.5327 - accuracy: 0.7799\n",
            " 27/300 [=>............................] - ETA: 1:58 - loss: 0.5322 - accuracy: 0.7792\n",
            " 28/300 [=>............................] - ETA: 1:58 - loss: 0.5317 - accuracy: 0.7785\n",
            " 29/300 [=>............................] - ETA: 1:57 - loss: 0.5313 - accuracy: 0.7780\n",
            " 30/300 [==>...........................] - ETA: 1:57 - loss: 0.5299 - accuracy: 0.7783\n",
            " 31/300 [==>...........................] - ETA: 1:56 - loss: 0.5273 - accuracy: 0.7795\n",
            " 32/300 [==>...........................] - ETA: 1:56 - loss: 0.5257 - accuracy: 0.7802\n",
            " 33/300 [==>...........................] - ETA: 1:55 - loss: 0.5251 - accuracy: 0.7802\n",
            " 34/300 [==>...........................] - ETA: 1:55 - loss: 0.5242 - accuracy: 0.7801\n",
            " 35/300 [==>...........................] - ETA: 1:54 - loss: 0.5234 - accuracy: 0.7799\n",
            " 36/300 [==>...........................] - ETA: 1:54 - loss: 0.5221 - accuracy: 0.7806\n",
            " 37/300 [==>...........................] - ETA: 1:54 - loss: 0.5216 - accuracy: 0.7800\n",
            " 38/300 [==>...........................] - ETA: 1:53 - loss: 0.5210 - accuracy: 0.7794\n",
            " 39/300 [==>...........................] - ETA: 1:53 - loss: 0.5207 - accuracy: 0.7787\n",
            " 40/300 [===>..........................] - ETA: 1:52 - loss: 0.5192 - accuracy: 0.7791\n",
            " 41/300 [===>..........................] - ETA: 1:52 - loss: 0.5185 - accuracy: 0.7785\n",
            " 42/300 [===>..........................] - ETA: 1:51 - loss: 0.5167 - accuracy: 0.7792\n",
            " 43/300 [===>..........................] - ETA: 1:51 - loss: 0.5154 - accuracy: 0.7794\n",
            " 44/300 [===>..........................] - ETA: 1:51 - loss: 0.5142 - accuracy: 0.7796\n",
            " 45/300 [===>..........................] - ETA: 1:50 - loss: 0.5132 - accuracy: 0.7796\n",
            " 46/300 [===>..........................] - ETA: 1:50 - loss: 0.5118 - accuracy: 0.7798\n",
            " 47/300 [===>..........................] - ETA: 1:49 - loss: 0.5110 - accuracy: 0.7796\n",
            " 48/300 [===>..........................] - ETA: 1:49 - loss: 0.5102 - accuracy: 0.7789\n",
            " 49/300 [===>..........................] - ETA: 1:48 - loss: 0.5089 - accuracy: 0.7788\n",
            " 50/300 [====>.........................] - ETA: 1:48 - loss: 0.5078 - accuracy: 0.7784\n",
            " 51/300 [====>.........................] - ETA: 1:47 - loss: 0.5058 - accuracy: 0.7790\n",
            " 52/300 [====>.........................] - ETA: 1:47 - loss: 0.5040 - accuracy: 0.7794\n",
            " 53/300 [====>.........................] - ETA: 1:47 - loss: 0.5021 - accuracy: 0.7799\n",
            " 54/300 [====>.........................] - ETA: 1:46 - loss: 0.5005 - accuracy: 0.7800\n",
            " 55/300 [====>.........................] - ETA: 1:46 - loss: 0.4991 - accuracy: 0.7799\n",
            " 56/300 [====>.........................] - ETA: 1:45 - loss: 0.4977 - accuracy: 0.7795\n",
            " 57/300 [====>.........................] - ETA: 1:45 - loss: 0.4972 - accuracy: 0.7797\n",
            " 58/300 [====>.........................] - ETA: 1:45 - loss: 0.4964 - accuracy: 0.7800\n",
            " 59/300 [====>.........................] - ETA: 1:44 - loss: 0.4956 - accuracy: 0.7801\n",
            " 60/300 [=====>........................] - ETA: 1:44 - loss: 0.4940 - accuracy: 0.7802\n",
            " 61/300 [=====>........................] - ETA: 1:43 - loss: 0.4925 - accuracy: 0.7805\n",
            " 62/300 [=====>........................] - ETA: 1:43 - loss: 0.4914 - accuracy: 0.7810\n",
            " 63/300 [=====>........................] - ETA: 1:42 - loss: 0.4896 - accuracy: 0.7812\n",
            " 64/300 [=====>........................] - ETA: 1:42 - loss: 0.4885 - accuracy: 0.7810\n",
            " 65/300 [=====>........................] - ETA: 1:42 - loss: 0.4871 - accuracy: 0.7813\n",
            " 66/300 [=====>........................] - ETA: 1:41 - loss: 0.4858 - accuracy: 0.7816\n",
            " 67/300 [=====>........................] - ETA: 1:41 - loss: 0.4844 - accuracy: 0.7815\n",
            " 68/300 [=====>........................] - ETA: 1:40 - loss: 0.4831 - accuracy: 0.7814\n",
            " 69/300 [=====>........................] - ETA: 1:40 - loss: 0.4822 - accuracy: 0.7812\n",
            " 70/300 [======>.......................] - ETA: 1:39 - loss: 0.4812 - accuracy: 0.7809\n",
            " 71/300 [======>.......................] - ETA: 1:39 - loss: 0.4798 - accuracy: 0.7810\n",
            " 72/300 [======>.......................] - ETA: 1:38 - loss: 0.4782 - accuracy: 0.7814\n",
            " 73/300 [======>.......................] - ETA: 1:38 - loss: 0.4769 - accuracy: 0.7815\n",
            " 74/300 [======>.......................] - ETA: 1:38 - loss: 0.4758 - accuracy: 0.7816\n",
            " 75/300 [======>.......................] - ETA: 1:37 - loss: 0.4744 - accuracy: 0.7819\n",
            " 76/300 [======>.......................] - ETA: 1:37 - loss: 0.4734 - accuracy: 0.7820\n",
            " 77/300 [======>.......................] - ETA: 1:36 - loss: 0.4721 - accuracy: 0.7822\n",
            " 78/300 [======>.......................] - ETA: 1:36 - loss: 0.4706 - accuracy: 0.7826\n",
            " 79/300 [======>.......................] - ETA: 1:36 - loss: 0.4691 - accuracy: 0.7829\n",
            " 80/300 [=======>......................] - ETA: 1:35 - loss: 0.4676 - accuracy: 0.7832\n",
            " 81/300 [=======>......................] - ETA: 1:35 - loss: 0.4665 - accuracy: 0.7834\n",
            " 82/300 [=======>......................] - ETA: 1:34 - loss: 0.4653 - accuracy: 0.7837\n",
            " 83/300 [=======>......................] - ETA: 1:34 - loss: 0.4640 - accuracy: 0.7842\n",
            " 84/300 [=======>......................] - ETA: 1:33 - loss: 0.4628 - accuracy: 0.7845\n",
            " 85/300 [=======>......................] - ETA: 1:33 - loss: 0.4616 - accuracy: 0.7845\n",
            " 86/300 [=======>......................] - ETA: 1:32 - loss: 0.4603 - accuracy: 0.7847\n",
            " 87/300 [=======>......................] - ETA: 1:32 - loss: 0.4590 - accuracy: 0.7851\n",
            " 88/300 [=======>......................] - ETA: 1:32 - loss: 0.4578 - accuracy: 0.7856\n",
            " 89/300 [=======>......................] - ETA: 1:31 - loss: 0.4564 - accuracy: 0.7860\n",
            " 90/300 [========>.....................] - ETA: 1:31 - loss: 0.4552 - accuracy: 0.7861\n",
            " 91/300 [========>.....................] - ETA: 1:30 - loss: 0.4540 - accuracy: 0.7863\n",
            " 92/300 [========>.....................] - ETA: 1:30 - loss: 0.4528 - accuracy: 0.7867\n",
            " 93/300 [========>.....................] - ETA: 1:29 - loss: 0.4516 - accuracy: 0.7871\n",
            " 94/300 [========>.....................] - ETA: 1:29 - loss: 0.4505 - accuracy: 0.7876\n",
            " 95/300 [========>.....................] - ETA: 1:29 - loss: 0.4493 - accuracy: 0.7880\n",
            " 96/300 [========>.....................] - ETA: 1:28 - loss: 0.4485 - accuracy: 0.7881\n",
            " 97/300 [========>.....................] - ETA: 1:28 - loss: 0.4471 - accuracy: 0.7886\n",
            " 98/300 [========>.....................] - ETA: 1:27 - loss: 0.4459 - accuracy: 0.7888\n",
            " 99/300 [========>.....................] - ETA: 1:27 - loss: 0.4448 - accuracy: 0.7889\n",
            "100/300 [=========>....................] - ETA: 1:26 - loss: 0.4439 - accuracy: 0.7893\n",
            "101/300 [=========>....................] - ETA: 1:26 - loss: 0.4428 - accuracy: 0.7897\n",
            "102/300 [=========>....................] - ETA: 1:26 - loss: 0.4416 - accuracy: 0.7902\n",
            "103/300 [=========>....................] - ETA: 1:25 - loss: 0.4406 - accuracy: 0.7905\n",
            "104/300 [=========>....................] - ETA: 1:25 - loss: 0.4393 - accuracy: 0.7910\n",
            "105/300 [=========>....................] - ETA: 1:24 - loss: 0.4382 - accuracy: 0.7915\n",
            "106/300 [=========>....................] - ETA: 1:24 - loss: 0.4372 - accuracy: 0.7918\n",
            "107/300 [=========>....................] - ETA: 1:23 - loss: 0.4360 - accuracy: 0.7923\n",
            "108/300 [=========>....................] - ETA: 1:23 - loss: 0.4348 - accuracy: 0.7927\n",
            "109/300 [=========>....................] - ETA: 1:22 - loss: 0.4337 - accuracy: 0.7932\n",
            "110/300 [==========>...................] - ETA: 1:22 - loss: 0.4328 - accuracy: 0.7935\n",
            "111/300 [==========>...................] - ETA: 1:22 - loss: 0.4315 - accuracy: 0.7940\n",
            "112/300 [==========>...................] - ETA: 1:21 - loss: 0.4306 - accuracy: 0.7945\n",
            "113/300 [==========>...................] - ETA: 1:21 - loss: 0.4296 - accuracy: 0.7949\n",
            "114/300 [==========>...................] - ETA: 1:20 - loss: 0.4287 - accuracy: 0.7954\n",
            "115/300 [==========>...................] - ETA: 1:20 - loss: 0.4277 - accuracy: 0.7958\n",
            "116/300 [==========>...................] - ETA: 1:19 - loss: 0.4267 - accuracy: 0.7962\n",
            "117/300 [==========>...................] - ETA: 1:19 - loss: 0.4257 - accuracy: 0.7967\n",
            "118/300 [==========>...................] - ETA: 1:19 - loss: 0.4248 - accuracy: 0.7970\n",
            "119/300 [==========>...................] - ETA: 1:18 - loss: 0.4239 - accuracy: 0.7974\n",
            "120/300 [===========>..................] - ETA: 1:18 - loss: 0.4231 - accuracy: 0.7978\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "121/300 [===========>..................] - ETA: 1:17 - loss: 0.4226 - accuracy: 0.7981\n",
            "122/300 [===========>..................] - ETA: 1:17 - loss: 0.4216 - accuracy: 0.7986\n",
            "123/300 [===========>..................] - ETA: 1:16 - loss: 0.4205 - accuracy: 0.7991\n",
            "124/300 [===========>..................] - ETA: 1:16 - loss: 0.4197 - accuracy: 0.7994\n",
            "125/300 [===========>..................] - ETA: 1:16 - loss: 0.4189 - accuracy: 0.7998\n",
            "126/300 [===========>..................] - ETA: 1:15 - loss: 0.4182 - accuracy: 0.8002\n",
            "127/300 [===========>..................] - ETA: 1:15 - loss: 0.4171 - accuracy: 0.8008\n",
            "128/300 [===========>..................] - ETA: 1:14 - loss: 0.4161 - accuracy: 0.8012\n",
            "129/300 [===========>..................] - ETA: 1:14 - loss: 0.4153 - accuracy: 0.8016\n",
            "130/300 [============>.................] - ETA: 1:13 - loss: 0.4144 - accuracy: 0.8020\n",
            "131/300 [============>.................] - ETA: 1:13 - loss: 0.4135 - accuracy: 0.8025\n",
            "132/300 [============>.................] - ETA: 1:12 - loss: 0.4127 - accuracy: 0.8030\n",
            "133/300 [============>.................] - ETA: 1:12 - loss: 0.4118 - accuracy: 0.8034\n",
            "134/300 [============>.................] - ETA: 1:12 - loss: 0.4110 - accuracy: 0.8039\n",
            "135/300 [============>.................] - ETA: 1:11 - loss: 0.4101 - accuracy: 0.8042\n",
            "136/300 [============>.................] - ETA: 1:11 - loss: 0.4092 - accuracy: 0.8047\n",
            "137/300 [============>.................] - ETA: 1:10 - loss: 0.4086 - accuracy: 0.8051\n",
            "138/300 [============>.................] - ETA: 1:10 - loss: 0.4077 - accuracy: 0.8055\n",
            "139/300 [============>.................] - ETA: 1:09 - loss: 0.4069 - accuracy: 0.8060\n",
            "140/300 [=============>................] - ETA: 1:09 - loss: 0.4060 - accuracy: 0.8065\n",
            "141/300 [=============>................] - ETA: 1:09 - loss: 0.4052 - accuracy: 0.8069\n",
            "142/300 [=============>................] - ETA: 1:08 - loss: 0.4044 - accuracy: 0.8074\n",
            "143/300 [=============>................] - ETA: 1:08 - loss: 0.4035 - accuracy: 0.8079\n",
            "144/300 [=============>................] - ETA: 1:07 - loss: 0.4030 - accuracy: 0.8082\n",
            "145/300 [=============>................] - ETA: 1:07 - loss: 0.4021 - accuracy: 0.8087\n",
            "146/300 [=============>................] - ETA: 1:06 - loss: 0.4013 - accuracy: 0.8091\n",
            "147/300 [=============>................] - ETA: 1:06 - loss: 0.4007 - accuracy: 0.8094\n",
            "148/300 [=============>................] - ETA: 1:06 - loss: 0.3999 - accuracy: 0.8099\n",
            "149/300 [=============>................] - ETA: 1:05 - loss: 0.3990 - accuracy: 0.8103\n",
            "150/300 [==============>...............] - ETA: 1:05 - loss: 0.3981 - accuracy: 0.8108\n",
            "151/300 [==============>...............] - ETA: 1:04 - loss: 0.3974 - accuracy: 0.8112\n",
            "152/300 [==============>...............] - ETA: 1:04 - loss: 0.3967 - accuracy: 0.8116\n",
            "153/300 [==============>...............] - ETA: 1:03 - loss: 0.3961 - accuracy: 0.8119\n",
            "154/300 [==============>...............] - ETA: 1:03 - loss: 0.3953 - accuracy: 0.8123\n",
            "155/300 [==============>...............] - ETA: 1:03 - loss: 0.3945 - accuracy: 0.8127\n",
            "156/300 [==============>...............] - ETA: 1:02 - loss: 0.3939 - accuracy: 0.8130\n",
            "157/300 [==============>...............] - ETA: 1:02 - loss: 0.3933 - accuracy: 0.8134\n",
            "158/300 [==============>...............] - ETA: 1:01 - loss: 0.3926 - accuracy: 0.8138\n",
            "159/300 [==============>...............] - ETA: 1:01 - loss: 0.3921 - accuracy: 0.8141\n",
            "160/300 [===============>..............] - ETA: 1:00 - loss: 0.3914 - accuracy: 0.8144\n",
            "161/300 [===============>..............] - ETA: 1:00 - loss: 0.3906 - accuracy: 0.8149\n",
            "162/300 [===============>..............] - ETA: 59s - loss: 0.3900 - accuracy: 0.8152 \n",
            "163/300 [===============>..............] - ETA: 59s - loss: 0.3892 - accuracy: 0.8156\n",
            "164/300 [===============>..............] - ETA: 59s - loss: 0.3885 - accuracy: 0.8160\n",
            "165/300 [===============>..............] - ETA: 58s - loss: 0.3881 - accuracy: 0.8162\n",
            "166/300 [===============>..............] - ETA: 58s - loss: 0.3877 - accuracy: 0.8165\n",
            "167/300 [===============>..............] - ETA: 57s - loss: 0.3870 - accuracy: 0.8168\n",
            "168/300 [===============>..............] - ETA: 57s - loss: 0.3863 - accuracy: 0.8172\n",
            "169/300 [===============>..............] - ETA: 56s - loss: 0.3858 - accuracy: 0.8175\n",
            "170/300 [================>.............] - ETA: 56s - loss: 0.3850 - accuracy: 0.8179\n",
            "171/300 [================>.............] - ETA: 56s - loss: 0.3844 - accuracy: 0.8183\n",
            "172/300 [================>.............] - ETA: 55s - loss: 0.3839 - accuracy: 0.8186\n",
            "173/300 [================>.............] - ETA: 55s - loss: 0.3835 - accuracy: 0.8188\n",
            "174/300 [================>.............] - ETA: 54s - loss: 0.3828 - accuracy: 0.8192\n",
            "175/300 [================>.............] - ETA: 54s - loss: 0.3823 - accuracy: 0.8194\n",
            "176/300 [================>.............] - ETA: 53s - loss: 0.3817 - accuracy: 0.8198\n",
            "177/300 [================>.............] - ETA: 53s - loss: 0.3811 - accuracy: 0.8201\n",
            "178/300 [================>.............] - ETA: 53s - loss: 0.3806 - accuracy: 0.8204\n",
            "179/300 [================>.............] - ETA: 52s - loss: 0.3799 - accuracy: 0.8207\n",
            "180/300 [=================>............] - ETA: 52s - loss: 0.3794 - accuracy: 0.8210\n",
            "181/300 [=================>............] - ETA: 51s - loss: 0.3787 - accuracy: 0.8214\n",
            "182/300 [=================>............] - ETA: 51s - loss: 0.3781 - accuracy: 0.8217\n",
            "183/300 [=================>............] - ETA: 50s - loss: 0.3775 - accuracy: 0.8220\n",
            "184/300 [=================>............] - ETA: 50s - loss: 0.3771 - accuracy: 0.8223\n",
            "185/300 [=================>............] - ETA: 49s - loss: 0.3764 - accuracy: 0.8226\n",
            "186/300 [=================>............] - ETA: 49s - loss: 0.3759 - accuracy: 0.8230\n",
            "187/300 [=================>............] - ETA: 49s - loss: 0.3753 - accuracy: 0.8233\n",
            "188/300 [=================>............] - ETA: 48s - loss: 0.3749 - accuracy: 0.8235\n",
            "189/300 [=================>............] - ETA: 48s - loss: 0.3745 - accuracy: 0.8238\n",
            "190/300 [==================>...........] - ETA: 47s - loss: 0.3739 - accuracy: 0.8241\n",
            "191/300 [==================>...........] - ETA: 47s - loss: 0.3733 - accuracy: 0.8244\n",
            "192/300 [==================>...........] - ETA: 46s - loss: 0.3726 - accuracy: 0.8248\n",
            "193/300 [==================>...........] - ETA: 46s - loss: 0.3719 - accuracy: 0.8251\n",
            "194/300 [==================>...........] - ETA: 46s - loss: 0.3714 - accuracy: 0.8254\n",
            "195/300 [==================>...........] - ETA: 45s - loss: 0.3709 - accuracy: 0.8257\n",
            "196/300 [==================>...........] - ETA: 45s - loss: 0.3705 - accuracy: 0.8259\n",
            "197/300 [==================>...........] - ETA: 44s - loss: 0.3701 - accuracy: 0.8261\n",
            "198/300 [==================>...........] - ETA: 44s - loss: 0.3696 - accuracy: 0.8264\n",
            "199/300 [==================>...........] - ETA: 43s - loss: 0.3690 - accuracy: 0.8267\n",
            "200/300 [===================>..........] - ETA: 43s - loss: 0.3686 - accuracy: 0.8270\n",
            "201/300 [===================>..........] - ETA: 43s - loss: 0.3680 - accuracy: 0.8273\n",
            "202/300 [===================>..........] - ETA: 42s - loss: 0.3677 - accuracy: 0.8275\n",
            "203/300 [===================>..........] - ETA: 42s - loss: 0.3670 - accuracy: 0.8278\n",
            "204/300 [===================>..........] - ETA: 41s - loss: 0.3666 - accuracy: 0.8281\n",
            "205/300 [===================>..........] - ETA: 41s - loss: 0.3659 - accuracy: 0.8285\n",
            "206/300 [===================>..........] - ETA: 40s - loss: 0.3655 - accuracy: 0.8287\n",
            "207/300 [===================>..........] - ETA: 40s - loss: 0.3649 - accuracy: 0.8290\n",
            "208/300 [===================>..........] - ETA: 40s - loss: 0.3645 - accuracy: 0.8293\n",
            "209/300 [===================>..........] - ETA: 39s - loss: 0.3640 - accuracy: 0.8295\n",
            "210/300 [====================>.........] - ETA: 39s - loss: 0.3636 - accuracy: 0.8298\n",
            "211/300 [====================>.........] - ETA: 38s - loss: 0.3633 - accuracy: 0.8300\n",
            "212/300 [====================>.........] - ETA: 38s - loss: 0.3628 - accuracy: 0.8302\n",
            "213/300 [====================>.........] - ETA: 37s - loss: 0.3624 - accuracy: 0.8305\n",
            "214/300 [====================>.........] - ETA: 37s - loss: 0.3619 - accuracy: 0.8308\n",
            "215/300 [====================>.........] - ETA: 36s - loss: 0.3614 - accuracy: 0.8310\n",
            "216/300 [====================>.........] - ETA: 36s - loss: 0.3608 - accuracy: 0.8313\n",
            "217/300 [====================>.........] - ETA: 36s - loss: 0.3607 - accuracy: 0.8315\n",
            "218/300 [====================>.........] - ETA: 35s - loss: 0.3602 - accuracy: 0.8317\n",
            "219/300 [====================>.........] - ETA: 35s - loss: 0.3598 - accuracy: 0.8319\n",
            "220/300 [=====================>........] - ETA: 34s - loss: 0.3594 - accuracy: 0.8321\n",
            "221/300 [=====================>........] - ETA: 34s - loss: 0.3589 - accuracy: 0.8324\n",
            "222/300 [=====================>........] - ETA: 33s - loss: 0.3585 - accuracy: 0.8327\n",
            "223/300 [=====================>........] - ETA: 33s - loss: 0.3581 - accuracy: 0.8328\n",
            "224/300 [=====================>........] - ETA: 33s - loss: 0.3578 - accuracy: 0.8331\n",
            "225/300 [=====================>........] - ETA: 32s - loss: 0.3572 - accuracy: 0.8334\n",
            "226/300 [=====================>........] - ETA: 32s - loss: 0.3568 - accuracy: 0.8336\n",
            "227/300 [=====================>........] - ETA: 31s - loss: 0.3564 - accuracy: 0.8338\n",
            "228/300 [=====================>........] - ETA: 31s - loss: 0.3558 - accuracy: 0.8341\n",
            "229/300 [=====================>........] - ETA: 30s - loss: 0.3554 - accuracy: 0.8344\n",
            "230/300 [======================>.......] - ETA: 30s - loss: 0.3548 - accuracy: 0.8347\n",
            "231/300 [======================>.......] - ETA: 30s - loss: 0.3544 - accuracy: 0.8349\n",
            "232/300 [======================>.......] - ETA: 29s - loss: 0.3539 - accuracy: 0.8351\n",
            "233/300 [======================>.......] - ETA: 29s - loss: 0.3535 - accuracy: 0.8354\n",
            "234/300 [======================>.......] - ETA: 28s - loss: 0.3531 - accuracy: 0.8356\n",
            "235/300 [======================>.......] - ETA: 28s - loss: 0.3526 - accuracy: 0.8359\n",
            "236/300 [======================>.......] - ETA: 27s - loss: 0.3523 - accuracy: 0.8360\n",
            "237/300 [======================>.......] - ETA: 27s - loss: 0.3520 - accuracy: 0.8362\n",
            "238/300 [======================>.......] - ETA: 26s - loss: 0.3517 - accuracy: 0.8364\n",
            "239/300 [======================>.......] - ETA: 26s - loss: 0.3513 - accuracy: 0.8366\n",
            "240/300 [=======================>......] - ETA: 26s - loss: 0.3510 - accuracy: 0.8369\n",
            "241/300 [=======================>......] - ETA: 25s - loss: 0.3505 - accuracy: 0.8371\n",
            "242/300 [=======================>......] - ETA: 25s - loss: 0.3503 - accuracy: 0.8372\n",
            "243/300 [=======================>......] - ETA: 24s - loss: 0.3499 - accuracy: 0.8374\n",
            "244/300 [=======================>......] - ETA: 24s - loss: 0.3496 - accuracy: 0.8376\n",
            "245/300 [=======================>......] - ETA: 23s - loss: 0.3493 - accuracy: 0.8378\n",
            "246/300 [=======================>......] - ETA: 23s - loss: 0.3488 - accuracy: 0.8380\n",
            "247/300 [=======================>......] - ETA: 23s - loss: 0.3485 - accuracy: 0.8382\n",
            "248/300 [=======================>......] - ETA: 22s - loss: 0.3482 - accuracy: 0.8384\n",
            "249/300 [=======================>......] - ETA: 22s - loss: 0.3478 - accuracy: 0.8386\n",
            "250/300 [========================>.....] - ETA: 21s - loss: 0.3474 - accuracy: 0.8388\n",
            "251/300 [========================>.....] - ETA: 21s - loss: 0.3470 - accuracy: 0.8390\n",
            "252/300 [========================>.....] - ETA: 20s - loss: 0.3467 - accuracy: 0.8392\n",
            "253/300 [========================>.....] - ETA: 20s - loss: 0.3463 - accuracy: 0.8394\n",
            "254/300 [========================>.....] - ETA: 20s - loss: 0.3459 - accuracy: 0.8396\n",
            "255/300 [========================>.....] - ETA: 19s - loss: 0.3456 - accuracy: 0.8398\n",
            "256/300 [========================>.....] - ETA: 19s - loss: 0.3454 - accuracy: 0.8400\n",
            "257/300 [========================>.....] - ETA: 18s - loss: 0.3449 - accuracy: 0.8402\n",
            "258/300 [========================>.....] - ETA: 18s - loss: 0.3446 - accuracy: 0.8404\n",
            "259/300 [========================>.....] - ETA: 17s - loss: 0.3442 - accuracy: 0.8406\n",
            "260/300 [=========================>....] - ETA: 17s - loss: 0.3439 - accuracy: 0.8407\n",
            "261/300 [=========================>....] - ETA: 16s - loss: 0.3435 - accuracy: 0.8410\n",
            "262/300 [=========================>....] - ETA: 16s - loss: 0.3431 - accuracy: 0.8412\n",
            "263/300 [=========================>....] - ETA: 16s - loss: 0.3428 - accuracy: 0.8414\n",
            "264/300 [=========================>....] - ETA: 15s - loss: 0.3424 - accuracy: 0.8416\n",
            "265/300 [=========================>....] - ETA: 15s - loss: 0.3421 - accuracy: 0.8417\n",
            "266/300 [=========================>....] - ETA: 14s - loss: 0.3417 - accuracy: 0.8419\n",
            "267/300 [=========================>....] - ETA: 14s - loss: 0.3413 - accuracy: 0.8422\n",
            "268/300 [=========================>....] - ETA: 13s - loss: 0.3409 - accuracy: 0.8424\n",
            "269/300 [=========================>....] - ETA: 13s - loss: 0.3405 - accuracy: 0.8426\n",
            "270/300 [==========================>...] - ETA: 13s - loss: 0.3403 - accuracy: 0.8427\n",
            "271/300 [==========================>...] - ETA: 12s - loss: 0.3399 - accuracy: 0.8429\n",
            "272/300 [==========================>...] - ETA: 12s - loss: 0.3396 - accuracy: 0.8431\n",
            "273/300 [==========================>...] - ETA: 11s - loss: 0.3393 - accuracy: 0.8433\n",
            "274/300 [==========================>...] - ETA: 11s - loss: 0.3390 - accuracy: 0.8434\n",
            "275/300 [==========================>...] - ETA: 10s - loss: 0.3387 - accuracy: 0.8436\n",
            "276/300 [==========================>...] - ETA: 10s - loss: 0.3383 - accuracy: 0.8438\n",
            "277/300 [==========================>...] - ETA: 10s - loss: 0.3380 - accuracy: 0.8440\n",
            "278/300 [==========================>...] - ETA: 9s - loss: 0.3377 - accuracy: 0.8442 \n",
            "279/300 [==========================>...] - ETA: 9s - loss: 0.3374 - accuracy: 0.8443\n",
            "280/300 [===========================>..] - ETA: 8s - loss: 0.3370 - accuracy: 0.8445\n",
            "281/300 [===========================>..] - ETA: 8s - loss: 0.3367 - accuracy: 0.8447\n",
            "282/300 [===========================>..] - ETA: 7s - loss: 0.3363 - accuracy: 0.8449\n",
            "283/300 [===========================>..] - ETA: 7s - loss: 0.3359 - accuracy: 0.8451\n",
            "284/300 [===========================>..] - ETA: 6s - loss: 0.3355 - accuracy: 0.8453\n",
            "285/300 [===========================>..] - ETA: 6s - loss: 0.3352 - accuracy: 0.8455\n",
            "286/300 [===========================>..] - ETA: 6s - loss: 0.3349 - accuracy: 0.8456\n",
            "287/300 [===========================>..] - ETA: 5s - loss: 0.3346 - accuracy: 0.8458\n",
            "288/300 [===========================>..] - ETA: 5s - loss: 0.3343 - accuracy: 0.8460\n",
            "289/300 [===========================>..] - ETA: 4s - loss: 0.3339 - accuracy: 0.8462\n",
            "290/300 [============================>.] - ETA: 4s - loss: 0.3335 - accuracy: 0.8464\n",
            "291/300 [============================>.] - ETA: 3s - loss: 0.3332 - accuracy: 0.8465\n",
            "292/300 [============================>.] - ETA: 3s - loss: 0.3328 - accuracy: 0.8467\n",
            "293/300 [============================>.] - ETA: 3s - loss: 0.3324 - accuracy: 0.8469\n",
            "294/300 [============================>.] - ETA: 2s - loss: 0.3320 - accuracy: 0.8471\n",
            "295/300 [============================>.] - ETA: 2s - loss: 0.3317 - accuracy: 0.8473\n",
            "296/300 [============================>.] - ETA: 1s - loss: 0.3313 - accuracy: 0.8475\n",
            "297/300 [============================>.] - ETA: 1s - loss: 0.3309 - accuracy: 0.8477\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.3306 - accuracy: 0.8479\n",
            "299/300 [============================>.] - ETA: 0s - loss: 0.3303 - accuracy: 0.8481\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.8482\n",
            "Epoch 1: loss improved from inf to 0.33015, saving model to unet_membrane.hdf5\n",
            "\n",
            "300/300 [==============================] - 139s 440ms/step - loss: 0.3301 - accuracy: 0.8482\n",
            "\n",
            " 1/30 [>.............................] - ETA: 1:00\n",
            " 3/30 [==>...........................] - ETA: 1s  \n",
            " 4/30 [===>..........................] - ETA: 1s\n",
            " 5/30 [====>.........................] - ETA: 1s\n",
            " 6/30 [=====>........................] - ETA: 1s\n",
            " 7/30 [======>.......................] - ETA: 1s\n",
            " 8/30 [=======>......................] - ETA: 1s\n",
            " 9/30 [========>.....................] - ETA: 1s\n",
            "10/30 [=========>....................] - ETA: 1s\n",
            "11/30 [==========>...................] - ETA: 1s\n",
            "12/30 [===========>..................] - ETA: 1s\n",
            "13/30 [============>.................] - ETA: 1s\n",
            "14/30 [=============>................] - ETA: 1s\n",
            "15/30 [==============>...............] - ETA: 1s\n",
            "16/30 [===============>..............] - ETA: 1s\n",
            "17/30 [================>.............] - ETA: 0s\n",
            "18/30 [=================>............] - ETA: 0s\n",
            "19/30 [==================>...........] - ETA: 0s\n",
            "20/30 [===================>..........] - ETA: 0s\n",
            "21/30 [====================>.........] - ETA: 0s\n",
            "22/30 [=====================>........] - ETA: 0s\n",
            "23/30 [======================>.......] - ETA: 0s\n",
            "24/30 [=======================>......] - ETA: 0s\n",
            "25/30 [========================>.....] - ETA: 0s\n",
            "26/30 [=========================>....] - ETA: 0s\n",
            "27/30 [==========================>...] - ETA: 0s\n",
            "28/30 [===========================>..] - ETA: 0s\n",
            "29/30 [============================>.] - ETA: 0s\n",
            "30/30 [==============================] - ETA: 0s\n",
            "30/30 [==============================] - 4s 76ms/step\n"
          ]
        }
      ],
      "source": [
        "!python main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VfkADrQ_47rX"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "dir_str = \"/unet/data/membrane/test\"\n",
        "imgs = glob.glob(dir_str + '/*' + '.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "colab_type": "code",
        "id": "QQdTPXPQ5EQL",
        "outputId": "9e88654a-1f61-40d0-e16a-bdce8c4d416a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import re\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "height = 256\n",
        "width = 256\n",
        "img_array = np.empty((0, height, width))\n",
        "n_imgs = len(imgs)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for itr, img in enumerate(imgs):\n",
        "        img_tensor = Image.open(img)\n",
        "        img_tensor = np.asarray(img_tensor)\n",
        "        img_tensor = cv2.resize(img_tensor, dsize=(height, width))\n",
        "        img_tensor = img_tensor.reshape(1, height, width)\n",
        "        img_array = np.append(img_array, img_tensor, axis=0)\n",
        "\n",
        "for itr, img in enumerate(img_array):\n",
        "    plt.subplot(int(np.sqrt(n_imgs))+1, int(np.sqrt(n_imgs))+1, itr+1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "iqikH6U79110",
        "outputId": "99af2202-1a55-4e19-e862-3a03d4687e9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kaggle API 1.5.6\n"
          ]
        }
      ],
      "source": [
        "!kaggle --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "Ie0zoYeK8Ybh",
        "outputId": "d131257a-605b-4814-cd77-cc81e287791b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading tgs-salt-identification-challenge.zip to d:\\Py4Me\\Tscripts\\Diver\\diveintocode-ml\\Sprint 19\\unet\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0.00/445M [00:00<?, ?B/s]\n",
            "  0%|          | 1.00M/445M [00:02<14:54, 520kB/s]\n",
            "  1%|          | 4.00M/445M [00:02<03:13, 2.39MB/s]\n",
            "  1%|          | 5.00M/445M [00:02<02:31, 3.04MB/s]\n",
            "  1%|▏         | 6.00M/445M [00:02<02:03, 3.73MB/s]\n",
            "  2%|▏         | 7.00M/445M [00:02<01:41, 4.50MB/s]\n",
            "  2%|▏         | 8.00M/445M [00:02<01:30, 5.07MB/s]\n",
            "  2%|▏         | 9.00M/445M [00:02<01:27, 5.20MB/s]\n",
            "  2%|▏         | 11.0M/445M [00:03<01:02, 7.33MB/s]\n",
            "  3%|▎         | 12.0M/445M [00:03<00:58, 7.79MB/s]\n",
            "  3%|▎         | 14.0M/445M [00:03<00:52, 8.64MB/s]\n",
            "  3%|▎         | 15.0M/445M [00:03<01:08, 6.60MB/s]\n",
            "  4%|▍         | 17.0M/445M [00:03<01:00, 7.44MB/s]\n",
            "  4%|▍         | 19.0M/445M [00:04<00:56, 7.89MB/s]\n",
            "  4%|▍         | 20.0M/445M [00:04<00:55, 8.07MB/s]\n",
            "  5%|▍         | 22.0M/445M [00:04<00:59, 7.40MB/s]\n",
            "  5%|▌         | 24.0M/445M [00:04<01:01, 7.12MB/s]\n",
            "  6%|▌         | 26.0M/445M [00:05<00:57, 7.60MB/s]\n",
            "  6%|▌         | 27.0M/445M [00:05<01:01, 7.14MB/s]\n",
            "  7%|▋         | 29.0M/445M [00:05<00:53, 8.17MB/s]\n",
            "  7%|▋         | 30.0M/445M [00:05<01:00, 7.14MB/s]\n",
            "  7%|▋         | 32.0M/445M [00:05<00:47, 9.12MB/s]\n",
            "  7%|▋         | 33.0M/445M [00:05<00:49, 8.69MB/s]\n",
            "  8%|▊         | 35.0M/445M [00:06<00:44, 9.68MB/s]\n",
            "  8%|▊         | 37.0M/445M [00:06<00:45, 9.36MB/s]\n",
            "  9%|▉         | 39.0M/445M [00:06<00:39, 10.8MB/s]\n",
            "  9%|▉         | 41.0M/445M [00:06<00:39, 10.7MB/s]\n",
            " 10%|▉         | 43.0M/445M [00:06<00:40, 10.5MB/s]\n",
            " 10%|█         | 45.0M/445M [00:07<00:50, 8.25MB/s]\n",
            " 11%|█         | 47.0M/445M [00:07<00:45, 9.24MB/s]\n",
            " 11%|█         | 48.0M/445M [00:07<00:45, 9.23MB/s]\n",
            " 11%|█         | 49.0M/445M [00:07<00:49, 8.38MB/s]\n",
            " 11%|█         | 50.0M/445M [00:07<00:51, 8.02MB/s]\n",
            " 11%|█▏        | 51.0M/445M [00:08<01:12, 5.68MB/s]\n",
            " 12%|█▏        | 52.0M/445M [00:08<01:06, 6.15MB/s]\n",
            " 12%|█▏        | 53.0M/445M [00:08<01:13, 5.57MB/s]\n",
            " 12%|█▏        | 54.0M/445M [00:08<01:04, 6.34MB/s]\n",
            " 12%|█▏        | 55.0M/445M [00:08<00:58, 7.00MB/s]\n",
            " 13%|█▎        | 56.0M/445M [00:08<00:52, 7.74MB/s]\n",
            " 13%|█▎        | 58.0M/445M [00:09<00:49, 8.27MB/s]\n",
            " 13%|█▎        | 60.0M/445M [00:09<00:47, 8.53MB/s]\n",
            " 14%|█▎        | 61.0M/445M [00:09<01:16, 5.23MB/s]\n",
            " 14%|█▍        | 63.0M/445M [00:10<01:14, 5.34MB/s]\n",
            " 15%|█▍        | 65.0M/445M [00:10<01:01, 6.43MB/s]\n",
            " 15%|█▍        | 66.0M/445M [00:10<01:00, 6.56MB/s]\n",
            " 15%|█▌        | 67.0M/445M [00:10<01:01, 6.44MB/s]\n",
            " 15%|█▌        | 68.0M/445M [00:11<01:31, 4.32MB/s]\n",
            " 16%|█▌        | 70.0M/445M [00:11<01:08, 5.74MB/s]\n",
            " 16%|█▌        | 71.0M/445M [00:11<01:02, 6.30MB/s]\n",
            " 16%|█▌        | 72.0M/445M [00:11<01:22, 4.72MB/s]\n",
            " 16%|█▋        | 73.0M/445M [00:12<01:12, 5.40MB/s]\n",
            " 17%|█▋        | 74.0M/445M [00:12<01:05, 5.95MB/s]\n",
            " 17%|█▋        | 75.0M/445M [00:12<01:09, 5.56MB/s]\n",
            " 17%|█▋        | 77.0M/445M [00:12<01:01, 6.22MB/s]\n",
            " 18%|█▊        | 79.0M/445M [00:12<00:47, 8.04MB/s]\n",
            " 18%|█▊        | 80.0M/445M [00:13<00:54, 7.00MB/s]\n",
            " 18%|█▊        | 81.0M/445M [00:13<00:50, 7.59MB/s]\n",
            " 18%|█▊        | 82.0M/445M [00:13<00:48, 7.90MB/s]\n",
            " 19%|█▉        | 84.0M/445M [00:13<00:38, 9.71MB/s]\n",
            " 19%|█▉        | 85.0M/445M [00:13<00:42, 8.97MB/s]\n",
            " 19%|█▉        | 86.0M/445M [00:13<00:41, 8.98MB/s]\n",
            " 20%|█▉        | 87.0M/445M [00:13<00:44, 8.48MB/s]\n",
            " 20%|██        | 89.0M/445M [00:13<00:33, 11.1MB/s]\n",
            " 20%|██        | 91.0M/445M [00:14<00:37, 9.96MB/s]\n",
            " 21%|██        | 93.0M/445M [00:14<00:46, 8.01MB/s]\n",
            " 21%|██        | 94.0M/445M [00:14<00:45, 8.02MB/s]\n",
            " 22%|██▏       | 96.0M/445M [00:14<00:41, 8.90MB/s]\n",
            " 22%|██▏       | 97.0M/445M [00:15<00:43, 8.31MB/s]\n",
            " 22%|██▏       | 99.0M/445M [00:15<00:40, 8.89MB/s]\n",
            " 22%|██▏       | 100M/445M [00:15<00:49, 7.25MB/s] \n",
            " 23%|██▎       | 102M/445M [00:15<00:44, 8.01MB/s]\n",
            " 23%|██▎       | 103M/445M [00:15<00:55, 6.49MB/s]\n",
            " 23%|██▎       | 104M/445M [00:16<01:01, 5.80MB/s]\n",
            " 24%|██▍       | 106M/445M [00:16<00:46, 7.56MB/s]\n",
            " 24%|██▍       | 108M/445M [00:16<00:43, 8.19MB/s]\n",
            " 25%|██▍       | 109M/445M [00:17<01:03, 5.57MB/s]\n",
            " 25%|██▌       | 112M/445M [00:17<00:41, 8.31MB/s]\n",
            " 25%|██▌       | 113M/445M [00:17<00:42, 8.11MB/s]\n",
            " 26%|██▌       | 114M/445M [00:17<00:48, 7.09MB/s]\n",
            " 26%|██▌       | 116M/445M [00:17<00:42, 8.09MB/s]\n",
            " 27%|██▋       | 118M/445M [00:17<00:35, 9.70MB/s]\n",
            " 27%|██▋       | 120M/445M [00:18<00:43, 7.82MB/s]\n",
            " 27%|██▋       | 121M/445M [00:18<00:42, 8.02MB/s]\n",
            " 27%|██▋       | 122M/445M [00:18<00:43, 7.70MB/s]\n",
            " 28%|██▊       | 124M/445M [00:18<00:41, 8.17MB/s]\n",
            " 28%|██▊       | 125M/445M [00:18<00:41, 7.98MB/s]\n",
            " 29%|██▊       | 127M/445M [00:19<00:44, 7.55MB/s]\n",
            " 29%|██▉       | 128M/445M [00:19<00:50, 6.56MB/s]\n",
            " 29%|██▉       | 130M/445M [00:19<00:45, 7.26MB/s]\n",
            " 29%|██▉       | 131M/445M [00:19<00:43, 7.54MB/s]\n",
            " 30%|██▉       | 133M/445M [00:20<00:39, 8.17MB/s]\n",
            " 30%|███       | 134M/445M [00:20<00:40, 7.96MB/s]\n",
            " 30%|███       | 135M/445M [00:20<00:50, 6.38MB/s]\n",
            " 31%|███       | 136M/445M [00:20<00:47, 6.83MB/s]\n",
            " 31%|███       | 137M/445M [00:20<00:56, 5.67MB/s]\n",
            " 31%|███       | 138M/445M [00:20<00:52, 6.16MB/s]\n",
            " 31%|███▏      | 140M/445M [00:21<00:42, 7.59MB/s]\n",
            " 32%|███▏      | 142M/445M [00:21<00:36, 8.69MB/s]\n",
            " 32%|███▏      | 143M/445M [00:21<00:35, 8.81MB/s]\n",
            " 32%|███▏      | 144M/445M [00:22<01:07, 4.66MB/s]\n",
            " 33%|███▎      | 146M/445M [00:22<00:52, 5.94MB/s]\n",
            " 33%|███▎      | 148M/445M [00:22<00:50, 6.20MB/s]\n",
            " 34%|███▎      | 150M/445M [00:22<00:49, 6.21MB/s]\n",
            " 34%|███▍      | 152M/445M [00:23<00:42, 7.19MB/s]\n",
            " 35%|███▍      | 154M/445M [00:23<00:39, 7.64MB/s]\n",
            " 35%|███▍      | 155M/445M [00:23<00:39, 7.71MB/s]\n",
            " 35%|███▌      | 156M/445M [00:23<00:39, 7.60MB/s]\n",
            " 36%|███▌      | 158M/445M [00:23<00:34, 8.80MB/s]\n",
            " 36%|███▌      | 159M/445M [00:24<00:42, 7.08MB/s]\n",
            " 36%|███▌      | 160M/445M [00:24<00:50, 5.94MB/s]\n",
            " 36%|███▌      | 161M/445M [00:24<00:52, 5.66MB/s]\n",
            " 36%|███▋      | 162M/445M [00:24<00:55, 5.38MB/s]\n",
            " 37%|███▋      | 164M/445M [00:25<00:56, 5.22MB/s]\n",
            " 37%|███▋      | 166M/445M [00:25<00:41, 7.00MB/s]\n",
            " 38%|███▊      | 167M/445M [00:25<00:57, 5.04MB/s]\n",
            " 38%|███▊      | 169M/445M [00:25<00:49, 5.88MB/s]\n",
            " 38%|███▊      | 170M/445M [00:26<00:45, 6.32MB/s]\n",
            " 38%|███▊      | 171M/445M [00:26<00:45, 6.36MB/s]\n",
            " 39%|███▊      | 172M/445M [00:26<00:43, 6.55MB/s]\n",
            " 39%|███▉      | 173M/445M [00:26<01:05, 4.33MB/s]\n",
            " 39%|███▉      | 175M/445M [00:26<00:44, 6.35MB/s]\n",
            " 40%|███▉      | 176M/445M [00:27<00:43, 6.52MB/s]\n",
            " 40%|███▉      | 177M/445M [00:27<00:39, 7.11MB/s]\n",
            " 40%|████      | 178M/445M [00:27<00:40, 6.99MB/s]\n",
            " 40%|████      | 179M/445M [00:27<00:39, 7.06MB/s]\n",
            " 40%|████      | 180M/445M [00:27<00:37, 7.32MB/s]\n",
            " 41%|████      | 181M/445M [00:27<00:34, 7.97MB/s]\n",
            " 41%|████      | 182M/445M [00:27<00:33, 8.30MB/s]\n",
            " 41%|████      | 183M/445M [00:27<00:31, 8.72MB/s]\n",
            " 41%|████▏     | 184M/445M [00:28<00:33, 8.25MB/s]\n",
            " 42%|████▏     | 185M/445M [00:28<00:39, 6.95MB/s]\n",
            " 42%|████▏     | 186M/445M [00:28<00:52, 5.14MB/s]\n",
            " 42%|████▏     | 188M/445M [00:28<00:43, 6.14MB/s]\n",
            " 43%|████▎     | 190M/445M [00:29<00:38, 6.85MB/s]\n",
            " 43%|████▎     | 191M/445M [00:29<00:44, 5.92MB/s]\n",
            " 43%|████▎     | 193M/445M [00:29<00:36, 7.25MB/s]\n",
            " 44%|████▎     | 194M/445M [00:29<00:39, 6.57MB/s]\n",
            " 44%|████▍     | 195M/445M [00:29<00:36, 7.13MB/s]\n",
            " 44%|████▍     | 196M/445M [00:30<01:22, 3.15MB/s]\n",
            " 45%|████▍     | 198M/445M [00:31<01:09, 3.74MB/s]\n",
            " 45%|████▌     | 201M/445M [00:31<00:45, 5.60MB/s]\n",
            " 45%|████▌     | 202M/445M [00:31<00:43, 5.82MB/s]\n",
            " 46%|████▌     | 204M/445M [00:31<00:34, 7.28MB/s]\n",
            " 46%|████▌     | 205M/445M [00:31<00:32, 7.71MB/s]\n",
            " 47%|████▋     | 207M/445M [00:32<00:28, 8.70MB/s]\n",
            " 47%|████▋     | 209M/445M [00:32<00:27, 9.01MB/s]\n",
            " 47%|████▋     | 210M/445M [00:32<00:28, 8.78MB/s]\n",
            " 47%|████▋     | 211M/445M [00:32<00:33, 7.25MB/s]\n",
            " 48%|████▊     | 212M/445M [00:32<00:34, 7.15MB/s]\n",
            " 48%|████▊     | 213M/445M [00:33<00:38, 6.33MB/s]\n",
            " 48%|████▊     | 215M/445M [00:33<00:36, 6.51MB/s]\n",
            " 49%|████▉     | 217M/445M [00:33<00:34, 6.92MB/s]\n",
            " 49%|████▉     | 218M/445M [00:33<00:39, 6.07MB/s]\n",
            " 49%|████▉     | 220M/445M [00:34<00:35, 6.70MB/s]\n",
            " 50%|████▉     | 221M/445M [00:34<00:42, 5.50MB/s]\n",
            " 50%|████▉     | 222M/445M [00:34<00:38, 6.01MB/s]\n",
            " 50%|█████     | 223M/445M [00:34<00:43, 5.39MB/s]\n",
            " 51%|█████     | 225M/445M [00:35<00:32, 7.05MB/s]\n",
            " 51%|█████     | 226M/445M [00:35<00:35, 6.48MB/s]\n",
            " 51%|█████     | 227M/445M [00:35<00:34, 6.61MB/s]\n",
            " 52%|█████▏    | 229M/445M [00:35<00:29, 7.55MB/s]\n",
            " 52%|█████▏    | 230M/445M [00:35<00:31, 7.19MB/s]\n",
            " 52%|█████▏    | 231M/445M [00:35<00:36, 6.15MB/s]\n",
            " 52%|█████▏    | 233M/445M [00:36<00:27, 8.11MB/s]\n",
            " 53%|█████▎    | 234M/445M [00:36<00:28, 7.88MB/s]\n",
            " 53%|█████▎    | 235M/445M [00:36<00:36, 6.00MB/s]\n",
            " 53%|█████▎    | 237M/445M [00:36<00:38, 5.60MB/s]\n",
            " 54%|█████▎    | 238M/445M [00:37<00:39, 5.53MB/s]\n",
            " 54%|█████▍    | 240M/445M [00:37<00:30, 7.12MB/s]\n",
            " 54%|█████▍    | 242M/445M [00:37<00:25, 8.25MB/s]\n",
            " 55%|█████▍    | 243M/445M [00:38<00:48, 4.40MB/s]\n",
            " 55%|█████▍    | 244M/445M [00:38<00:46, 4.48MB/s]\n",
            " 55%|█████▌    | 246M/445M [00:38<00:32, 6.32MB/s]\n",
            " 56%|█████▌    | 247M/445M [00:38<00:33, 6.17MB/s]\n",
            " 56%|█████▌    | 248M/445M [00:38<00:34, 5.90MB/s]\n",
            " 56%|█████▌    | 250M/445M [00:39<00:27, 7.38MB/s]\n",
            " 56%|█████▋    | 251M/445M [00:39<00:27, 7.31MB/s]\n",
            " 57%|█████▋    | 253M/445M [00:39<00:23, 8.45MB/s]\n",
            " 57%|█████▋    | 254M/445M [00:39<00:23, 8.37MB/s]\n",
            " 57%|█████▋    | 255M/445M [00:39<00:23, 8.38MB/s]\n",
            " 58%|█████▊    | 256M/445M [00:39<00:28, 7.02MB/s]\n",
            " 58%|█████▊    | 258M/445M [00:40<00:25, 7.68MB/s]\n",
            " 58%|█████▊    | 259M/445M [00:40<00:24, 8.10MB/s]\n",
            " 59%|█████▊    | 261M/445M [00:40<00:21, 9.11MB/s]\n",
            " 59%|█████▉    | 263M/445M [00:40<00:21, 8.96MB/s]\n",
            " 60%|█████▉    | 265M/445M [00:40<00:20, 9.07MB/s]\n",
            " 60%|██████    | 267M/445M [00:41<00:17, 10.4MB/s]\n",
            " 61%|██████    | 269M/445M [00:41<00:18, 9.69MB/s]\n",
            " 61%|██████    | 271M/445M [00:41<00:17, 10.3MB/s]\n",
            " 61%|██████▏   | 273M/445M [00:41<00:19, 9.02MB/s]\n",
            " 62%|██████▏   | 274M/445M [00:41<00:19, 9.24MB/s]\n",
            " 62%|██████▏   | 275M/445M [00:42<00:21, 8.33MB/s]\n",
            " 62%|██████▏   | 276M/445M [00:42<00:21, 8.12MB/s]\n",
            " 62%|██████▏   | 277M/445M [00:42<00:21, 8.25MB/s]\n",
            " 63%|██████▎   | 278M/445M [00:42<00:23, 7.43MB/s]\n",
            " 63%|██████▎   | 280M/445M [00:42<00:18, 9.39MB/s]\n",
            " 63%|██████▎   | 282M/445M [00:42<00:17, 9.90MB/s]\n",
            " 64%|██████▎   | 283M/445M [00:42<00:18, 9.12MB/s]\n",
            " 64%|██████▍   | 285M/445M [00:43<00:17, 9.30MB/s]\n",
            " 65%|██████▍   | 287M/445M [00:43<00:15, 10.5MB/s]\n",
            " 65%|██████▌   | 289M/445M [00:43<00:15, 10.6MB/s]\n",
            " 65%|██████▌   | 291M/445M [00:43<00:19, 8.35MB/s]\n",
            " 66%|██████▌   | 293M/445M [00:44<00:18, 8.61MB/s]\n",
            " 66%|██████▌   | 294M/445M [00:44<00:18, 8.54MB/s]\n",
            " 66%|██████▋   | 295M/445M [00:44<00:19, 8.17MB/s]\n",
            " 67%|██████▋   | 296M/445M [00:44<00:19, 7.84MB/s]\n",
            " 67%|██████▋   | 298M/445M [00:44<00:16, 9.15MB/s]\n",
            " 67%|██████▋   | 299M/445M [00:44<00:16, 9.03MB/s]\n",
            " 67%|██████▋   | 300M/445M [00:45<00:22, 6.82MB/s]\n",
            " 68%|██████▊   | 303M/445M [00:45<00:13, 10.6MB/s]\n",
            " 69%|██████▊   | 305M/445M [00:45<00:17, 8.58MB/s]\n",
            " 69%|██████▉   | 306M/445M [00:45<00:23, 6.16MB/s]\n",
            " 70%|██████▉   | 309M/445M [00:46<00:15, 9.43MB/s]\n",
            " 70%|██████▉   | 311M/445M [00:46<00:15, 9.08MB/s]\n",
            " 70%|███████   | 313M/445M [00:46<00:19, 6.97MB/s]\n",
            " 71%|███████   | 315M/445M [00:46<00:16, 8.23MB/s]\n",
            " 71%|███████▏  | 317M/445M [00:47<00:19, 6.78MB/s]\n",
            " 72%|███████▏  | 320M/445M [00:47<00:14, 9.16MB/s]\n",
            " 72%|███████▏  | 322M/445M [00:48<00:17, 7.33MB/s]\n",
            " 73%|███████▎  | 324M/445M [00:48<00:14, 8.65MB/s]\n",
            " 73%|███████▎  | 326M/445M [00:48<00:17, 7.08MB/s]\n",
            " 74%|███████▎  | 327M/445M [00:48<00:16, 7.44MB/s]\n",
            " 74%|███████▍  | 328M/445M [00:48<00:17, 6.84MB/s]\n",
            " 74%|███████▍  | 329M/445M [00:49<00:17, 7.09MB/s]\n",
            " 74%|███████▍  | 330M/445M [00:49<00:15, 7.63MB/s]\n",
            " 74%|███████▍  | 331M/445M [00:49<00:18, 6.57MB/s]\n",
            " 75%|███████▍  | 333M/445M [00:49<00:13, 8.93MB/s]\n",
            " 75%|███████▌  | 335M/445M [00:49<00:16, 7.14MB/s]\n",
            " 76%|███████▌  | 336M/445M [00:49<00:15, 7.54MB/s]\n",
            " 76%|███████▌  | 338M/445M [00:50<00:11, 9.42MB/s]\n",
            " 76%|███████▋  | 340M/445M [00:50<00:13, 8.16MB/s]\n",
            " 77%|███████▋  | 342M/445M [00:50<00:12, 8.75MB/s]\n",
            " 77%|███████▋  | 343M/445M [00:50<00:14, 7.58MB/s]\n",
            " 78%|███████▊  | 345M/445M [00:50<00:11, 9.24MB/s]\n",
            " 78%|███████▊  | 347M/445M [00:51<00:14, 7.15MB/s]\n",
            " 79%|███████▊  | 349M/445M [00:51<00:11, 8.43MB/s]\n",
            " 79%|███████▊  | 350M/445M [00:51<00:11, 8.57MB/s]\n",
            " 79%|███████▉  | 351M/445M [00:51<00:14, 6.81MB/s]\n",
            " 79%|███████▉  | 353M/445M [00:52<00:14, 6.78MB/s]\n",
            " 80%|███████▉  | 355M/445M [00:52<00:16, 5.75MB/s]\n",
            " 81%|████████  | 358M/445M [00:52<00:10, 8.59MB/s]\n",
            " 81%|████████  | 360M/445M [00:53<00:09, 9.22MB/s]\n",
            " 81%|████████▏ | 362M/445M [00:53<00:09, 9.49MB/s]\n",
            " 82%|████████▏ | 364M/445M [00:53<00:09, 8.71MB/s]\n",
            " 82%|████████▏ | 365M/445M [00:53<00:11, 7.30MB/s]\n",
            " 83%|████████▎ | 367M/445M [00:53<00:10, 8.12MB/s]\n",
            " 83%|████████▎ | 369M/445M [00:54<00:08, 9.06MB/s]\n",
            " 83%|████████▎ | 370M/445M [00:54<00:08, 9.07MB/s]\n",
            " 83%|████████▎ | 371M/445M [00:54<00:09, 8.27MB/s]\n",
            " 84%|████████▎ | 372M/445M [00:54<00:09, 8.32MB/s]\n",
            " 84%|████████▍ | 375M/445M [00:54<00:07, 10.1MB/s]\n",
            " 85%|████████▍ | 376M/445M [00:55<00:08, 8.22MB/s]\n",
            " 85%|████████▌ | 379M/445M [00:55<00:05, 11.6MB/s]\n",
            " 86%|████████▌ | 381M/445M [00:55<00:06, 9.61MB/s]\n",
            " 86%|████████▌ | 383M/445M [00:55<00:06, 10.7MB/s]\n",
            " 87%|████████▋ | 385M/445M [00:55<00:06, 9.74MB/s]\n",
            " 87%|████████▋ | 387M/445M [00:56<00:05, 10.6MB/s]\n",
            " 88%|████████▊ | 389M/445M [00:56<00:06, 9.57MB/s]\n",
            " 88%|████████▊ | 390M/445M [00:56<00:06, 8.70MB/s]\n",
            " 88%|████████▊ | 392M/445M [00:56<00:06, 8.67MB/s]\n",
            " 89%|████████▊ | 394M/445M [00:56<00:05, 9.55MB/s]\n",
            " 89%|████████▉ | 395M/445M [00:57<00:05, 9.15MB/s]\n",
            " 89%|████████▉ | 397M/445M [00:57<00:05, 9.14MB/s]\n",
            " 90%|████████▉ | 398M/445M [00:57<00:05, 9.14MB/s]\n",
            " 90%|████████▉ | 400M/445M [00:57<00:05, 9.28MB/s]\n",
            " 90%|█████████ | 402M/445M [00:57<00:04, 10.8MB/s]\n",
            " 91%|█████████ | 404M/445M [00:57<00:04, 9.93MB/s]\n",
            " 91%|█████████ | 405M/445M [00:58<00:04, 8.76MB/s]\n",
            " 92%|█████████▏| 407M/445M [00:58<00:04, 8.47MB/s]\n",
            " 92%|█████████▏| 409M/445M [00:58<00:03, 10.4MB/s]\n",
            " 92%|█████████▏| 411M/445M [00:58<00:03, 9.09MB/s]\n",
            " 93%|█████████▎| 412M/445M [00:59<00:04, 7.93MB/s]\n",
            " 93%|█████████▎| 414M/445M [00:59<00:03, 8.47MB/s]\n",
            " 94%|█████████▎| 416M/445M [00:59<00:03, 8.39MB/s]\n",
            " 94%|█████████▍| 418M/445M [00:59<00:02, 10.1MB/s]\n",
            " 94%|█████████▍| 420M/445M [00:59<00:02, 9.44MB/s]\n",
            " 95%|█████████▍| 422M/445M [01:00<00:02, 9.06MB/s]\n",
            " 95%|█████████▌| 424M/445M [01:00<00:02, 9.37MB/s]\n",
            " 96%|█████████▌| 425M/445M [01:00<00:02, 9.44MB/s]\n",
            " 96%|█████████▌| 427M/445M [01:00<00:01, 9.90MB/s]\n",
            " 97%|█████████▋| 429M/445M [01:00<00:01, 10.9MB/s]\n",
            " 97%|█████████▋| 431M/445M [01:01<00:01, 9.72MB/s]\n",
            " 97%|█████████▋| 432M/445M [01:01<00:01, 8.12MB/s]\n",
            " 97%|█████████▋| 433M/445M [01:01<00:01, 8.02MB/s]\n",
            " 98%|█████████▊| 435M/445M [01:01<00:01, 9.45MB/s]\n",
            " 98%|█████████▊| 436M/445M [01:01<00:01, 8.71MB/s]\n",
            " 98%|█████████▊| 437M/445M [01:01<00:01, 7.54MB/s]\n",
            " 99%|█████████▉| 439M/445M [01:02<00:01, 4.67MB/s]\n",
            " 99%|█████████▉| 441M/445M [01:02<00:00, 5.60MB/s]\n",
            "100%|█████████▉| 443M/445M [01:03<00:00, 6.58MB/s]\n",
            "100%|█████████▉| 444M/445M [01:03<00:00, 6.81MB/s]\n",
            "100%|██████████| 445M/445M [01:03<00:00, 7.37MB/s]\n"
          ]
        }
      ],
      "source": [
        "#!kaggle competitions download -c tgs-salt-identification-challenge --force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "colab_type": "code",
        "id": "agtfAtPtFNox",
        "outputId": "717f7ae5-ab81-4917-e5a1-07bfddc98bde"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ADMIN\\AppData\\Local\\Temp/ipykernel_3500/1593646407.py:20: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(myGene,steps_per_epoch=300,epochs=3,callbacks=[model_checkpoint])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4000 images belonging to 1 classes.\n",
            "Found 4000 images belonging to 1 classes.\n",
            "Epoch 1/3\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.6967 - accuracy: 0.7358\n",
            "Epoch 1: loss improved from inf to 0.69670, saving model to unet_membrane.hdf5\n",
            "300/300 [==============================] - 141s 447ms/step - loss: 0.6967 - accuracy: 0.7358\n",
            "Epoch 2/3\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.7445\n",
            "Epoch 2: loss improved from 0.69670 to 0.68517, saving model to unet_membrane.hdf5\n",
            "300/300 [==============================] - 135s 448ms/step - loss: 0.6852 - accuracy: 0.7445\n",
            "Epoch 3/3\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.6789 - accuracy: 0.7616\n",
            "Epoch 3: loss improved from 0.68517 to 0.67886, saving model to unet_membrane.hdf5\n",
            "300/300 [==============================] - 135s 450ms/step - loss: 0.6789 - accuracy: 0.7616\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x195f3760790>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from model import *\n",
        "from data import *\n",
        "\n",
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=0.05,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "myGene = trainGenerator(2,\n",
        "                        '../train data',\n",
        "                        'images',\n",
        "                        'masks',\n",
        "                        data_gen_args,save_to_dir = None,\n",
        "                        )\n",
        "\n",
        "model = unet()\n",
        "model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit_generator(myGene,steps_per_epoch=300,epochs=3,callbacks=[model_checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "aGgpBmy3IRHj",
        "outputId": "32ad9934-f3bd-4be2-eca9-426b3cf00099"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18000"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t_list = glob.glob('../test data/images' + '/*' + \".png\")\n",
        "len(t_list) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZkAH-CbWYXsk"
      },
      "outputs": [],
      "source": [
        "def testGenerator(test_path,num_image = 30,\n",
        "                  target_size = (256,256),\n",
        "                  flag_multi_class = False,\n",
        "                  as_gray = True):\n",
        "    for i in range(num_image):\n",
        "        img = io.imread(os.path.join(t_list[i]),as_gray = as_gray)\n",
        "        img = img / 255\n",
        "        img = trans.resize(img,target_size)\n",
        "        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
        "        img = np.reshape(img,(1,)+img.shape)\n",
        "        yield img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "iWbR5aTuYpvv",
        "outputId": "42237f25-19f7-4d7b-c295-a82d5b3510f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ADMIN\\AppData\\Local\\Temp/ipykernel_3500/3853285550.py:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  results = model.predict_generator(testGene,30,verbose=1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 2s 82ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        }
      ],
      "source": [
        "testGene = testGenerator(\"../test data/images\")\n",
        "results = model.predict_generator(testGene,30,verbose=1)\n",
        "saveResult(\"../test data/results\",results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "colab_type": "code",
        "id": "jbzek68qzn0-",
        "outputId": "a2a242e1-2c29-4f73-c6d4-92347bd7c1b2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 30 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pre_list = glob.glob('../test data/results' + '/*' + \".png\")\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import re\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "height = 256\n",
        "width = 256\n",
        "img_array = np.empty((0, height, width))\n",
        "n_imgs = len(pre_list)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for itr, img in enumerate(pre_list):\n",
        "        img_tensor = Image.open(img)\n",
        "        img_tensor = np.asarray(img_tensor)\n",
        "        img_tensor = cv2.resize(img_tensor, dsize=(height, width))\n",
        "        img_tensor = img_tensor.reshape(1, height, width)\n",
        "        img_array = np.append(img_array, img_tensor, axis=0)\n",
        "\n",
        "for itr, img in enumerate(img_array):\n",
        "    plt.subplot(int(np.sqrt(n_imgs))+1, int(np.sqrt(n_imgs))+1, itr+1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pxuDnIFmseAr"
      },
      "source": [
        "## Problem 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0kv53T6zsgRs"
      },
      "source": [
        "**Read the Paper (https://arxiv.org/pdf/1505.04597.pdf) and the Code.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SbyRJvWksuBf"
      },
      "source": [
        "- In this study, they offer a network and training technique that heavily relies on data augmentation. For more exact segmentation findings, the completely conventional network has been tweaked and expanded.\n",
        "- We can see from the code that the implementation is done on many layers. The data.py package includes methods for converting image data to numerical data (adjustData), expanding image data for training (trainGenerator), reading the test image (trainGenerator), normalizing (labelVisualize), and saving the estimation results (saveResults) (saveResult). The different instantiations are in main.py, and the model.py is where the model is defined, such as pooling, activation, and up-sampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the end of my assignment. Thank you for reading!\n",
        "\n",
        "Most of it are from instructors' help, thank you very much. I make sure to try many times before look for your help. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Sprint_19.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
