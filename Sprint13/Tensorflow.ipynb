{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Student Name: Huynh Truong Tu\n"," Below is my assignment for Sprint13's \"Tensorflow\""]},{"cell_type":"markdown","metadata":{},"source":["-------------------------------------------------------------------------------------------"]},{"cell_type":"markdown","metadata":{},"source":["# Intro to tensorflow"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["import tensorflow.compat.v1 as tf\n","tf.disable_eager_execution()"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["12\n"]}],"source":["a = tf.constant(5)\n","b = tf.constant(7)\n","add = tf.add(a, b)\n","sess = tf.Session()\n","output = sess.run(add)\n","print(output) # 12\n","sess.close()"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["12\n","52\n"]}],"source":["c = tf.placeholder(tf.int32)\n","d = tf.placeholder(tf.int32)\n","add = tf.add(c, d)\n","sess = tf.Session()\n","output = sess.run(add, feed_dict={c:5, d:7})\n","print(output) # 12\n","output = sess.run(add, feed_dict={c:20, d:32})\n","print(output) # 52\n","sess.close()\n"]},{"cell_type":"markdown","metadata":{},"source":["### NOTE:\n","Following tensorflow 2 from now on."]},{"cell_type":"markdown","metadata":{},"source":["# Logistic regress on Tensorflow"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["import numpy as np\n","x_train = np.array([[0,0],[0,1],[1,0],[1,1]])\n","y_train = np.array([[0],[0],[0],[1]])"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["x = tf.placeholder(tf.float32, [None, 2])\n","t = tf.placeholder(tf.float32, [None, 1])"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["W = tf.Variable(tf.zeros([2,1]))\n","b = tf.Variable(tf.zeros([1]))"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["y = tf.sigmoid(tf.matmul(x, W) + b)\n","cross_entropy = tf.reduce_sum(-t * tf.log(y) - (1 - t) * tf.log(1 - y))"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["correct_prediction = tf.equal(tf.sign(y - 0.5), tf.sign(t - 0.5))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["sess = tf.Session()\n","sess.run(tf.global_variables_initializer())"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch: 0, Accuracy: 0.750000\n","epoch: 100, Accuracy: 1.000000\n","epoch: 200, Accuracy: 1.000000\n","epoch: 300, Accuracy: 1.000000\n","epoch: 400, Accuracy: 1.000000\n","epoch: 500, Accuracy: 1.000000\n","epoch: 600, Accuracy: 1.000000\n","epoch: 700, Accuracy: 1.000000\n","epoch: 800, Accuracy: 1.000000\n","epoch: 900, Accuracy: 1.000000\n"]}],"source":["for epoch in range(1000):\n","    sess.run(train_step, feed_dict={\n","        x:x_train,\n","        t:y_train\n","    })\n","# Display the correct answer rate every 100 times\n","    if epoch % 100 == 0:\n","        acc_val = sess.run(\n","            accuracy, feed_dict={\n","                x:x_train,\n","                t:y_train})\n","        print ('epoch: %d, Accuracy: %f'\n","               %(epoch, acc_val))"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ True]\n"," [ True]\n"," [ True]\n"," [ True]]\n","[[1.9654632e-04]\n"," [4.9049824e-02]\n"," [4.9049824e-02]\n"," [9.3120384e-01]]\n"]}],"source":["#Check if the learning result is correct\n","classified = sess.run(correct_prediction, feed_dict={\n","    x:x_train,\n","    t:y_train\n","})\n","#Check output y\n","prob = sess.run(y, feed_dict={\n","    x:x_train,\n","    t:y_train\n","})\n","print(classified)\n","# [[ True]\n","# [ True]\n","# [ True]\n","# [ True]]\n","\n","print(prob)\n","# [[  1.96514215e-04]\n","# [  4.90498319e-02]\n","# [  4.90498319e-02]\n","# [  9.31203783e-01]]"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["W: [[5.5699544]\n"," [5.5699544]]\n","b: [-8.534579]\n"]}],"source":["print('W:', sess.run(W))\n","print('b:', sess.run(b))\n","# W: [[ 5.5699544]\n","# [ 5.5699544]]\n","# b: [-8.53457928]"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["sess.close()"]},{"cell_type":"markdown","metadata":{},"source":["# Tensorflow (v1)"]},{"cell_type":"markdown","metadata":{},"source":["# Problem 1 - Looking back on the scratch"]},{"cell_type":"markdown","metadata":{},"source":["### Steps to build a ML model\n","1. Load\n","2. Define model (class) along with needed stuffs (params, input shapes,..., procedure, batch ...)\n","3. Init stuff and use the model"]},{"cell_type":"markdown","metadata":{},"source":["# Problem 2 - Correspond between scratch and tensorflow"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ADMIN\\AppData\\Local\\Temp/ipykernel_3444/1202908980.py:45: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0, loss : 26.6982, val_loss : 312.7151, acc : 0.375\n","Epoch 1, loss : 23.9825, val_loss : 279.9050, acc : 0.375\n","Epoch 2, loss : 21.3399, val_loss : 248.1234, acc : 0.375\n","Epoch 3, loss : 18.7862, val_loss : 217.3301, acc : 0.375\n","Epoch 4, loss : 16.3442, val_loss : 187.9264, acc : 0.375\n","Epoch 5, loss : 13.9856, val_loss : 159.4701, acc : 0.375\n","Epoch 6, loss : 11.6769, val_loss : 131.5804, acc : 0.375\n","Epoch 7, loss : 9.4153, val_loss : 104.1883, acc : 0.375\n","Epoch 8, loss : 7.2025, val_loss : 77.2788, acc : 0.375\n","Epoch 9, loss : 5.0426, val_loss : 50.8798, acc : 0.375\n","test_acc : 0.500\n"]}],"source":["\"\"\"\n","Binary classification of Iris dataset using neural network implemented in TensorFlow\n","\"\"\"\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","#Load dataset\n","df = pd.read_csv(\"Iris.csv\")\n","\n","#Condition extraction from data frame\n","df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n","y = df[\"Species\"]\n","X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n","# NumPy 配列に変換\n","X = np.array(X)\n","y = np.array(y)\n","# Convert label to number\n","y[y == \"Iris-versicolor\"] = 0\n","y[y == \"Iris-virginica\"] = 1\n","y = y.astype(np.int64)[:, np.newaxis]\n","#Split into train and test\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","# さらにtrainとvalに分割\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","class GetMiniBatch:\n","    \"\"\"\n","    Iterator to get a mini-batch\n","    Parameters\n","    ----------\n","    X : The following forms of ndarray, shape (n_samples, n_features)\n","      Training data\n","    y : The following form of ndarray, shape (n_samples, 1)\n","      Correct answer value\n","    batch_size : int\n","      Batch size\n","    seed : int\n","      NumPy random number seed\n","    \"\"\"\n","    def __init__(self, X, y, batch_size = 10, seed=0):\n","        self.batch_size = batch_size\n","        np.random.seed(seed)\n","        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n","        self.X = X[shuffle_index]\n","        self.y = y[shuffle_index]\n","        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n","    def __len__(self):\n","        return self._stop\n","    def __getitem__(self,item):\n","        p0 = item*self.batch_size\n","        p1 = item*self.batch_size + self.batch_size\n","        return self.X[p0:p1], self.y[p0:p1]        \n","    def __iter__(self):\n","        self._counter = 0\n","        return self\n","    def __next__(self):\n","        if self._counter >= self._stop:\n","            raise StopIteration()\n","        p0 = self._counter*self.batch_size\n","        p1 = self._counter*self.batch_size + self.batch_size\n","        self._counter += 1\n","        return self.X[p0:p1], self.y[p0:p1]\n","# Hyperparameter settings\n","learning_rate = 0.001\n","batch_size = 10\n","num_epochs = 10\n","n_hidden1 = 50\n","n_hidden2 = 100\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","n_classes = 1\n","#Determine the shape of the argument to be passed to the calculation graph\n","X = tf.placeholder(\"float\", [None, n_input])\n","Y = tf.placeholder(\"float\", [None, n_classes])\n","# train mini batch iterator\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","def example_net(x):\n","    \"\"\"\n","    Simple 3-layer neural network\n","    \"\"\"\n","    tf.random.set_random_seed(0)\n","    # Declaration of weight and bias\n","    weights = {\n","        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n","        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n","        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n","    }\n","    biases = {\n","        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n","        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n","        'b3': tf.Variable(tf.random_normal([n_classes]))\n","    }\n","    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n","    layer_1 = tf.nn.relu(layer_1)\n","    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n","    layer_2 = tf.nn.relu(layer_2)\n","    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.add and + are equivalent\n","    return layer_output\n","#Read network structure                              \n","logits = example_net(X)\n","# Objective function\n","loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n","# Optimization method\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","train_op = optimizer.minimize(loss_op)\n","# Estimated result\n","correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n","#Indicator value calculation\n","accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","#Initialization of variable\n","init = tf.global_variables_initializer()\n","\n","#Run calculation graph\n","with tf.Session() as sess:\n","    sess.run(init)\n","    for epoch in range(num_epochs):\n","        #Loop for each epoch\n","        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int64)\n","        total_loss = 0\n","        total_acc = 0\n","        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","            # Loop for each mini-batch\n","            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})            \n","            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            total_loss += loss\n","        total_loss /= n_samples\n","\n","        val_loss, acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n","        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}\".format(epoch, total_loss, val_loss, acc))\n","    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n","    print(\"test_acc : {:.3f}\".format(test_acc))\n"]},{"cell_type":"markdown","metadata":{},"source":["### Steps to build in tensorflow\n","1. Load dataset\n","2. Define model and it's flow\n","   1. Define parameters (variable) and inputs (placeholders)\n","   2. Define model's prediction (or forward flow)\n","   3. Define models' loss function\n","   4. Get an optimizer\n","   5. Define the traing flow\n","      - Optimize\n","      - Training scores\n","      - Loss\n","      - Log,...\n","3. Prepare epoch and batch\n","4. Initialize paremeters\n","5.  Start a session\n","  - Train in batches\n","  - Use the model and stuss defined in tf syntax\n","6.  Close session"]},{"cell_type":"markdown","metadata":{},"source":["**Tensorflow 1.0 has a lazy execution approach to it.**"]},{"cell_type":"markdown","metadata":{},"source":["# Problem 3 - Create a model of Iris using all three types of objective variables"]},{"cell_type":"markdown","metadata":{},"source":["## Data Prep"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["shape:  (150, 6)\n","   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n","0   1            5.1           3.5            1.4           0.2  Iris-setosa\n","1   2            4.9           3.0            1.4           0.2  Iris-setosa\n","2   3            4.7           3.2            1.3           0.2  Iris-setosa\n","3   4            4.6           3.1            1.5           0.2  Iris-setosa\n","4   5            5.0           3.6            1.4           0.2  Iris-setosa\n"]}],"source":["#load dataset\n","df = pd.read_csv('Iris.csv')\n","\n","print('shape: ', df.shape)\n","print(df.head(5))"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X shape: (150, 4)\n","   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n","0            5.1           3.5            1.4           0.2\n","1            4.9           3.0            1.4           0.2\n","2            4.7           3.2            1.3           0.2\n","3            4.6           3.1            1.5           0.2\n","4            5.0           3.6            1.4           0.2\n"]}],"source":["# predictor\n","X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n","print('X shape:', X.shape)\n","print(X.head(5))"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["y shape:  (150,)\n","0    Iris-setosa\n","1    Iris-setosa\n","2    Iris-setosa\n","3    Iris-setosa\n","4    Iris-setosa\n","Name: Species, dtype: object\n"]}],"source":["# label\n","y = df['Species']\n","print('y shape: ', y.shape)\n","print(y.head(5))"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(150, 4) (150,)\n"]}],"source":["# Convert to numpy\n","X = np.array(X)\n","y = np.array(y)\n","print(X.shape, y.shape)"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["init shape y:  (150,)\n","shape:  (150, 3)\n","[[1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]]\n"]}],"source":["# Encode y from text to number label\n","print('init shape y: ', y.shape)\n","#label encode\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","y = LabelEncoder().fit_transform(y)\n","#reshape for onehot use\n","y = y.reshape(-1,1)\n","enc = OneHotEncoder()\n","y = enc.fit_transform(y).toarray()\n","print('shape: ', y.shape)\n","print(y[:5])"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train/Test size:  [(135, 4), (15, 4), (135, 3), (15, 3)]\n","Train/Test size:  [(108, 4), (27, 4), (108, 3), (27, 3)]\n"]}],"source":["from sklearn.model_selection import train_test_split\n","# train test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.9)\n","print('Train/Test size: ', [data.shape for data in [X_train, X_test, y_train, y_test]])\n","# train validation split\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size = 0.8)\n","print('Train/Test size: ', [data.shape for data in [X_train, X_val, y_train, y_val]])"]},{"cell_type":"markdown","metadata":{},"source":["## Model Prep"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["input nodes:  4\n","sample size:  108\n","prediction classes:  3\n"]}],"source":["# some variables\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","n_classes = y_train.shape[1]\n","\n","print('input nodes: ', n_input)\n","print('sample size: ', n_samples)\n","print('prediction classes: ', n_classes)"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["minibatch prepared!\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\ADMIN\\AppData\\Local\\Temp/ipykernel_3444/1202908980.py:45: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n"]}],"source":["# train mini batch iterator\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","\n","print('minibatch prepared!')"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["HYPER PARAMS\n","alpha learning rate:  0.001\n","batch size:  10\n","epoch num 100\n","n_hidden1:  50\n","n_hidden2:  100\n"]}],"source":["# Hyperparameter settings\n","learning_rate = 0.001\n","batch_size = 10\n","num_epochs = 100\n","n_hidden1 = 50\n","n_hidden2 = 100\n","\n","print('HYPER PARAMS')\n","print('alpha learning rate: ', learning_rate)\n","print('batch size: ', batch_size)\n","print('epoch num', num_epochs)\n","print('n_hidden1: ', n_hidden1)\n","print('n_hidden2: ', n_hidden2)"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X holder:  Tensor(\"Placeholder_14:0\", shape=(None, 4), dtype=float32)\n","Y holder:  Tensor(\"Placeholder_15:0\", shape=(None, 3), dtype=float32)\n"]}],"source":["#Determine the shape of the argument to be passed to the calculation graph\n","X = tf.placeholder(\"float\", [None, n_input])\n","Y = tf.placeholder(\"float\", [None, n_classes])\n","print('X holder: ',X)\n","print('Y holder: ', Y)"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"markdown","metadata":{},"source":["### Test layer"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["w: <tf.Variable 'Variable_18:0' shape=(4, 3) dtype=float32>\n","b: <tf.Variable 'Variable_19:0' shape=(3,) dtype=float32>\n"]}],"source":["# weight\n","w1 = tf.Variable(tf.random_normal([n_input, n_classes]))\n","b1 = tf.Variable(tf.random_normal([n_classes]))\n","print('w:', w1)\n","print('b:', b1)"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X:  Tensor(\"Placeholder_14:0\", shape=(None, 4), dtype=float32)\n","after matrix multiplication: Tensor(\"MatMul_9:0\", shape=(None, 3), dtype=float32)\n","after adding bias: Tensor(\"Add_13:0\", shape=(None, 3), dtype=float32)\n","after activation:  Tensor(\"Relu_5:0\", shape=(None, 3), dtype=float32)\n"]}],"source":["# layer\n","print('X: ', X)\n","layer1 = tf.matmul(X, w1)\n","print('after matrix multiplication:', layer1)\n","layer1 = tf.add(layer1, b1)\n","print('after adding bias:', layer1)\n","layer1 = tf.nn.relu(layer1)\n","print('after activation: ', layer1)"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["forward shape:  (108, 3)\n","forward:  [ 2.8272464  0.        11.3075695]\n"]}],"source":["session = tf.Session()\n","def do(stuff, input):\n","  return session.run(stuff, feed_dict = input)\n","def prep_session():\n","  session.run(tf.global_variables_initializer())\n","\n","prep_session()\n","forward = do(layer1, {X: X_train, Y: y_train})\n","print('forward shape: ', forward.shape)\n","print('forward: ', forward[0])\n"]},{"cell_type":"markdown","metadata":{},"source":["## Objective Function"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["loss: Tensor(\"Mean_8:0\", shape=(), dtype=float32)\n"]}],"source":["logits = layer1 # assuming 1 layer model\n","loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n","print('loss:', loss_op)\n","\n","\n","# the equivalent or the tf.softmax's implementation!\n","softmax = tf.nn.softmax(logits)\n","loss_op2 = -tf.reduce_sum(Y * tf.log(softmax), 1)\n","loss_op2 = tf.reduce_mean(loss_op2)"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["y_true:  [[0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]]\n","loss:  8.445068\n","loss2:  8.445068\n"]}],"source":["# test loss op\n","tf.set_random_seed(0)\n","\n","x_in, y_in = X_train[:5], y_train[:5]\n","run = lambda x: do(x, {X: x_in, Y: y_in})\n","print('y_true: ', y_in)\n","\n","loss = run(loss_op)\n","print('loss: ', loss)\n","loss2 = run(loss_op2)\n","print('loss2: ', loss2.mean())"]},{"cell_type":"markdown","metadata":{},"source":["## Prediction"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["logits:  [[ 2.8272464  0.        11.3075695]\n"," [ 4.3492875  0.        12.723299 ]\n"," [ 3.602052   0.        11.18089  ]\n"," [ 3.6349647  0.        11.244568 ]\n"," [ 3.4191263  0.        10.493351 ]]\n","pred:  [[0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]]\n"]}],"source":["def prediction_function(logits):\n","  pred = np.argmax(logits, axis = 1).reshape(-1,1)\n","  return enc.transform(pred).toarray()\n","logits_ = run(logits)\n","print('logits: ', logits_)\n","print('pred: ', prediction_function(logits_))\n"]},{"cell_type":"markdown","metadata":{},"source":["## Optimizer"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<tensorflow.python.training.adam.AdamOptimizer object at 0x000001505E296A60>\n"]}],"source":["optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","print(optimizer)"]},{"cell_type":"markdown","metadata":{},"source":["## Some Metrics"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy_function:  0.2\n"]}],"source":["# accuracy\n","def accuracy_function(pred, real):\n","  correct_pred = np.argmax(pred,axis = 1) == np.argmax(real,axis = 1)\n","  return correct_pred.mean()\n","pred = prediction_function(logits_)\n","real = y_in\n","print('accuracy_function: ', accuracy_function(pred,real))"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ADMIN\\AppData\\Local\\Temp/ipykernel_3444/1202908980.py:45: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0 Result -- tot_loss : 0.57, tot_acc : 0.36, val_loss : 5.98, val_acc : 0.30\n","Epoch 9 Result -- tot_loss : 0.46, tot_acc : 0.36, val_loss : 4.70, val_acc : 0.30\n","Epoch 19 Result -- tot_loss : 0.34, tot_acc : 0.36, val_loss : 3.50, val_acc : 0.30\n","Epoch 29 Result -- tot_loss : 0.29, tot_acc : 0.37, val_loss : 2.91, val_acc : 0.26\n","Epoch 39 Result -- tot_loss : 0.25, tot_acc : 0.40, val_loss : 2.47, val_acc : 0.41\n","Epoch 49 Result -- tot_loss : 0.21, tot_acc : 0.56, val_loss : 2.08, val_acc : 0.44\n","Epoch 59 Result -- tot_loss : 0.17, tot_acc : 0.62, val_loss : 1.70, val_acc : 0.56\n","Epoch 69 Result -- tot_loss : 0.13, tot_acc : 0.66, val_loss : 1.34, val_acc : 0.59\n","Epoch 79 Result -- tot_loss : 0.11, tot_acc : 0.66, val_loss : 1.05, val_acc : 0.63\n","Epoch 89 Result -- tot_loss : 0.09, tot_acc : 0.67, val_loss : 0.91, val_acc : 0.67\n","Epoch 99 Result -- tot_loss : 0.09, tot_acc : 0.67, val_loss : 0.84, val_acc : 0.63\n"]}],"source":["train_optimizer = optimizer.minimize(loss_op)\n","\n","def accuracy(logits, y):\n","  prediction = prediction_function(logits)\n","  acc = accuracy_function(prediction, y)\n","  return acc\n","\n","def train_batch(mini_batch_x, mini_batch_y):\n","  input_xy = {X: mini_batch_x, Y: mini_batch_y}\n","  run = lambda x: do(x, input_xy)\n","  # train\n","  run(train_optimizer)\n","  # loss\n","  batch_loss= run(loss_op)\n","  # accuracy\n","  batch_acc = accuracy(run(logits), mini_batch_y)\n","  return batch_loss, batch_acc\n","\n","def train_epoch(X_val, y_val, iterator, verbose= False):\n","  #Loop for each epoch\n","  total_loss = 0\n","  total_acc = 0\n","  # train\n","  for i, (mini_batch_x, mini_batch_y) in enumerate(iterator):\n","      batch_loss, batch_acc = train_batch(mini_batch_x, mini_batch_y)\n","      total_loss += batch_loss\n","      total_acc += batch_acc * batch_size\n","      if verbose:\n","        print(\"Batch: {}, b_loss: {:.3f}, b_acc: {:.3f}\".format(i, batch_loss, batch_acc))\n","  total_loss /= n_samples\n","  total_acc /= n_samples\n","\n","  input_xy = {X: X_val, Y: y_val}\n","  run = lambda x: do(x, input_xy)\n","  val_loss = run(loss_op)\n","  val_acc = accuracy(run(logits), y_val)\n","  return total_loss, total_acc, val_loss, val_acc\n","\n","def train(X_train, y_train, X_val, y_val, epoch = 10, verbose_interval = 10):\n","  iterator = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","  for i in range(epoch):\n","    # print('Starting epoch: ', i)\n","    total_loss, total_acc, val_loss, val_acc = train_epoch(X_val, y_val, iterator)\n","    if (i+1)%verbose_interval == 0 or i == 0:\n","      print(\"Epoch {} Result -- tot_loss : {:.2f}, tot_acc : {:.2f}, val_loss : {:.2f}, val_acc : {:.2f}\".format(i, total_loss, total_acc, val_loss, val_acc))\n","\n","    # print('______')\n","\n","session.close()\n","session = tf.Session()\n","prep_session()\n","train(X_train, y_train, X_val, y_val, epoch = 100, verbose_interval = 10)"]},{"cell_type":"markdown","metadata":{},"source":["# Problem 4 - Creating a model of house prices"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>MSSubClass</th>\n","      <th>MSZoning</th>\n","      <th>LotFrontage</th>\n","      <th>LotArea</th>\n","      <th>Street</th>\n","      <th>Alley</th>\n","      <th>LotShape</th>\n","      <th>LandContour</th>\n","      <th>Utilities</th>\n","      <th>...</th>\n","      <th>PoolArea</th>\n","      <th>PoolQC</th>\n","      <th>Fence</th>\n","      <th>MiscFeature</th>\n","      <th>MiscVal</th>\n","      <th>MoSold</th>\n","      <th>YrSold</th>\n","      <th>SaleType</th>\n","      <th>SaleCondition</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>65.0</td>\n","      <td>8450</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2008</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>208500</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>20</td>\n","      <td>RL</td>\n","      <td>80.0</td>\n","      <td>9600</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2007</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>181500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>68.0</td>\n","      <td>11250</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>2008</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>223500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>70</td>\n","      <td>RL</td>\n","      <td>60.0</td>\n","      <td>9550</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2006</td>\n","      <td>WD</td>\n","      <td>Abnorml</td>\n","      <td>140000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>84.0</td>\n","      <td>14260</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>2008</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>250000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 81 columns</p>\n","</div>"],"text/plain":["   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n","0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n","1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n","2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n","3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n","4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n","\n","  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n","0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n","1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n","2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n","3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n","4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n","\n","  YrSold  SaleType  SaleCondition  SalePrice  \n","0   2008        WD         Normal     208500  \n","1   2007        WD         Normal     181500  \n","2   2008        WD         Normal     223500  \n","3   2006        WD        Abnorml     140000  \n","4   2008        WD         Normal     250000  \n","\n","[5 rows x 81 columns]"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["# data set\n","house_price_pd = pd.read_csv('./houseprice_train.csv')\n","house_price_pd.head()"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["selected:  (1460, 3) Index(['GrLivArea', 'YearBuilt', 'SalePrice'], dtype='object')\n","   GrLivArea  YearBuilt  SalePrice\n","0       1710       2003     208500\n","1       1262       1976     181500\n","2       1786       2001     223500\n","3       1717       1915     140000\n","4       2198       2000     250000\n"]}],"source":["# selection\n","selected = house_price_pd[['GrLivArea', 'YearBuilt','SalePrice']]\n","print('selected: ', selected.shape, selected.columns)\n","print(selected.head())"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["GrLivArea    0\n","YearBuilt    0\n","SalePrice    0\n","dtype: int64\n"]}],"source":["# check nan\n","print(selected.isna().sum(axis = 0))"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                    mean           std\n","GrLivArea    1515.463699    525.480383\n","YearBuilt    1971.267808     30.202904\n","SalePrice  180921.195890  79442.502883\n","           mean       std\n","0 -1.277517e-16  1.000343\n","1  1.046347e-15  1.000343\n","2  1.362685e-16  1.000343\n","(1460, 2) [[ 0.37033344  1.05099379]\n"," [-0.48251191  0.15673371]\n"," [ 0.51501256  0.9847523 ]]\n","(1460, 1) [[0.34727322]\n"," [0.00728832]\n"," [0.53615372]]\n"]}],"source":["# normalize\n","print(selected.describe().transpose()[['mean', 'std']])\n","\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","scaled = scaler.fit_transform(selected)\n","print(pd.DataFrame(scaled).describe().transpose()[['mean', 'std']])\n","\n","explainatory = scaled[:,:-1]\n","objective = scaled[:,-1].reshape(-1,1)\n","print(explainatory.shape, explainatory[:3])\n","print(objective.shape, objective[:3])"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train shape:  [(1168, 2), (292, 2), (1168, 1), (292, 1)]\n"]}],"source":["# train test split\n","from sklearn.model_selection import train_test_split\n","X_train, X_val, y_train, y_val = train_test_split(explainatory, objective, train_size = 0.8)\n","print('train shape: ', [i.shape for i in [X_train, X_val, y_train, y_val]])"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["# prep vars\n","input_dimention = X_train.shape[-1]\n","batch_size = 20\n","lr = 0.1\n"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor(\"Placeholder_16:0\", shape=(None, 2), dtype=float32) Tensor(\"Placeholder_17:0\", shape=(None, 1), dtype=float32)\n"]}],"source":["# placeholder\n","X = tf.placeholder(\"float\", [None, input_dimention])\n","Y = tf.placeholder(\"float\", [None, 1])\n","print(X,Y)"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[],"source":["# model\n","w = tf.Variable(tf.random_normal([input_dimention, 1]))\n","b = tf.Variable(tf.random_normal([1]))\n","linear = tf.matmul(X, w)\n","linear = tf.add(linear, b)\n","\n","model = linear"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[],"source":["# loss\n","loss = Y - model\n","loss = tf.math.square(loss)\n","loss = tf.math.reduce_mean(loss) / 2\n","\n","# optimizer\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n","optimize_operation = optimizer.minimize(loss)"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1168, 2)\n","Ilteration: 0, SSE_train: 2.559596538543701, SSE_val: 2.71960186958313\n","Ilteration: 9, SSE_train: 0.559020459651947, SSE_val: 0.6395063996315002\n","Ilteration: 19, SSE_train: 0.2301533818244934, SSE_val: 0.2698774039745331\n","Ilteration: 29, SSE_train: 0.17963533103466034, SSE_val: 0.2065722644329071\n","Ilteration: 39, SSE_train: 0.17091837525367737, SSE_val: 0.19398769736289978\n","Ilteration: 49, SSE_train: 0.16932176053524017, SSE_val: 0.19117355346679688\n","Ilteration: 59, SSE_train: 0.16902121901512146, SSE_val: 0.19046470522880554\n","Ilteration: 69, SSE_train: 0.16896399855613708, SSE_val: 0.190261110663414\n","Ilteration: 79, SSE_train: 0.16895300149917603, SSE_val: 0.1901945322751999\n","Ilteration: 89, SSE_train: 0.1689509153366089, SSE_val: 0.1901702731847763\n","Ilteration: 99, SSE_train: 0.16895049810409546, SSE_val: 0.19016072154045105\n"]}],"source":["# train\n","def _train(X_train, y_train, X_val, y_val):\n","  input_xy = {X: X_train, Y: y_train}\n","  run = lambda x: do(x, input_xy)\n","  # train\n","  run(optimize_operation)\n","  # predict\n","  train_loss =  run(loss)\n","  input_xy = {X: X_val, Y: y_val}\n","  val_loss = run(loss)\n","  return train_loss, val_loss\n","\n","def train(X_train, y_train, X_val, y_val, epoch = 100, print_interval = 10):\n","  print(X_train.shape)\n","  for i in range(epoch): \n","    train_loss, val_loss = _train(X_train, y_train, X_val, y_val)\n","    if (i + 1) % print_interval == 0 or i == 0:\n","      print(f'Ilteration: {i}, SSE_train: {train_loss}, SSE_val: {val_loss}')\n","\n","session.close()\n","session = tf.Session()\n","prep_session()\n","train(X_train, y_train, X_val, y_val)"]},{"cell_type":"markdown","metadata":{},"source":["# Problem 5 - Creating a MNIST model"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train/val\n","[(3600, 28, 28, 1), (900, 28, 28, 1), (3600, 10), (900, 10)]\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\ADMIN\\AppData\\Local\\Temp/ipykernel_3444/417275906.py:14: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  X_train = X_train.astype(np.float)\n","C:\\Users\\ADMIN\\AppData\\Local\\Temp/ipykernel_3444/417275906.py:15: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  X_test = X_test.astype(np.float)\n"]}],"source":["#data set\n","from keras.datasets import mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","#random subset since the data is too large\n","from sklearn.model_selection import train_test_split\n","X_train, _, y_train, _ = train_test_split(X_train, y_train, train_size=0.075)\n","\n","#reshape and add one channel to X\n","X_train = np.expand_dims(X_train, axis=-1)\n","X_test = np.expand_dims(X_test, axis=-1)\n","\n","#scaling\n","X_train = X_train.astype(np.float)\n","X_test = X_test.astype(np.float)\n","X_train /= 255\n","X_test /= 255\n","#one hot encode for multiclass labels!\n","from sklearn.preprocessing import OneHotEncoder\n","enc = OneHotEncoder(handle_unknown='ignore', sparse=True)\n","y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis]).toarray()\n","y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n","\n","#validation split\n","x_train, x_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, train_size=0.8)\n","print('train/val')\n","print([i.shape for i in [x_train, x_val, y_train, y_val]])"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["label sample: \n"," [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"]}],"source":["print('label sample: \\n', y_train[1])"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(4500, 28, 28, 1)\n","input_shape:  (28, 28, 1)\n","output_shape:  (10,)\n","n_classes:  10\n","init_in_channels:  1\n","Tensor(\"Placeholder_18:0\", shape=(None, 28, 28, 1), dtype=float32) Tensor(\"Placeholder_19:0\", shape=(None, 10), dtype=float32)\n"]}],"source":["print(X_train.shape)\n","# prep vars\n","input_shape = X_train.shape[1:]\n","print('input_shape: ', input_shape)\n","output_shape = y_train.shape[1:]\n","print('output_shape: ', output_shape)\n","n_classes = output_shape[0]\n","print('n_classes: ', n_classes)\n","init_in_channels = input_shape[-1]\n","print('init_in_channels: ', init_in_channels)\n","\n","# Place holders\n","X = tf.placeholder('float', [None, *input_shape])\n","Y = tf.placeholder('float', [None, *output_shape])\n","print(X,Y)"]},{"cell_type":"markdown","metadata":{},"source":["### Model\n","VGG16"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ADMIN\\AppData\\Local\\Temp/ipykernel_3444/2029434593.py:56: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  fc1 = tf.layers.dense(flatten, units = 4096, activation = 'relu')\n","C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\legacy_tf_layers\\core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs)\n","C:\\Users\\ADMIN\\AppData\\Local\\Temp/ipykernel_3444/2029434593.py:57: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  fc2 = tf.layers.dense(fc1, units = n_classes, activation = 'softmax')\n"]},{"name":"stdout","output_type":"stream","text":["---------------------------------------\n","Tensor(\"Relu_6:0\", shape=(None, 28, 28, 64), dtype=float32)\n","Tensor(\"MaxPool:0\", shape=(None, 14, 14, 64), dtype=float32)\n","Tensor(\"Relu_7:0\", shape=(None, 14, 14, 128), dtype=float32)\n","Tensor(\"MaxPool_1:0\", shape=(None, 7, 7, 128), dtype=float32)\n","Tensor(\"Relu_8:0\", shape=(None, 7, 7, 256), dtype=float32)\n","Tensor(\"MaxPool_2:0\", shape=(None, 4, 4, 256), dtype=float32)\n","Tensor(\"Reshape:0\", shape=(None, 4096), dtype=float32)\n","Tensor(\"dense/Relu:0\", shape=(None, 4096), dtype=float32)\n","Tensor(\"dense_1/Softmax:0\", shape=(None, 10), dtype=float32)\n","---------------------------------------\n"]}],"source":["import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n","\n","def conv2d(x, W, b, strides=1):\n","    # print(f'Making conv2d -- in:{x.shape}, weight: {W.shape}, bias: {b.shape}')\n","    # Conv2D wrapper, with bias and relu activation\n","    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n","    x = tf.nn.bias_add(x, b)\n","    return tf.nn.relu(x)\n","\n","def maxpool2d(x, k=2):\n","    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')\n","\n","def make_var(shape, name = 'LongVar'):\n","  return tf.Variable(tf.random_normal([*shape]), name = name)\n","def relu(input_):\n","  return tf.nn.relu(input_)\n","\n","def VGG16(): #structure of VGG16\n","  weight_biases = {\n","\n","    # !1\n","    'conv1.1' : [\n","      make_var(shape = [3,3, init_in_channels,64], name = 'w1'),\n","      make_var(shape = [64], name = 'b1')\n","    ],\n","\n","    # !2\n","    'conv2.1' : [\n","      make_var(shape = [3,3, 64,128], name = 'w2'),\n","      make_var(shape = [128], name = 'b2')\n","    ],\n","\n","    # !3\n","    'conv3.1' : [\n","      make_var(shape = [3,3, 128,256], name = 'w3'),\n","      make_var(shape = [256], name = 'b3')\n","    ],\n","  }\n","\n","  # first \n","  first = conv2d(X, *weight_biases['conv1.1'])\n","  firstpool = maxpool2d(first, k = 2)\n","  # second\n","  second = conv2d(firstpool, *weight_biases['conv2.1'])\n","  secondpool = maxpool2d(second, k = 2)\n","  # # third\n","  third = conv2d(secondpool, *weight_biases['conv3.1'])\n","  thirdpool = maxpool2d(third, k = 2)\n","\n","  # flatten\n","  last_conv_layer = thirdpool\n","  flatted_shape = np.array(last_conv_layer.shape[1:]).prod()\n","  flatten = tf.reshape(last_conv_layer, [-1, flatted_shape])\n","  #fcs\n","  fc1 = tf.layers.dense(flatten, units = 4096, activation = 'relu')\n","  fc2 = tf.layers.dense(fc1, units = n_classes, activation = 'softmax')\n","\n","  result = fc2\n","  layers = [first, firstpool, second, secondpool, third, thirdpool, flatten, fc1, fc2]\n","  verbose = True\n","  if verbose: \n","    print('---------------------------------------')\n","    for layer in layers:\n","      if verbose: print(layer)\n","    print('---------------------------------------')\n","  return result\n","\n","model = VGG16()\n","logits = model\n","\n","#loss\n","loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n","#opt\n","optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n","train_optimizer = optimizer.minimize(loss_op)\n","#accuracy\n","accuracy = tf.math.reduce_mean(tf.keras.metrics.categorical_accuracy(logits, Y))"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[(3600, 28, 28, 1), (3600, 10), (900, 28, 28, 1), (900, 10)]\n","WARNING:tensorflow:From C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:247: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n","Instructions for updating:\n","Use `tf.global_variables_initializer` instead.\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\ADMIN\\AppData\\Local\\Temp/ipykernel_3444/1202908980.py:45: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0, loss : 3.9329, val_loss : 2.3789, acc : 0.082\n","Epoch 1, loss : 3.9329, val_loss : 2.3789, acc : 0.082\n","Epoch 2, loss : 3.9329, val_loss : 2.3789, acc : 0.082\n","Epoch 3, loss : 3.9329, val_loss : 2.3789, acc : 0.082\n","Epoch 4, loss : 3.9329, val_loss : 2.3789, acc : 0.082\n","Epoch 5, loss : 3.9329, val_loss : 2.3789, acc : 0.082\n","Epoch 6, loss : 3.9329, val_loss : 2.3789, acc : 0.082\n","Epoch 7, loss : 3.9329, val_loss : 2.3789, acc : 0.082\n","Epoch 8, loss : 3.9329, val_loss : 2.3789, acc : 0.082\n","Epoch 9, loss : 3.9329, val_loss : 2.3789, acc : 0.082\n"]}],"source":["#Run calculation graph\n","with tf.Session() as sess:\n","  X_train, y_train, X_val, y_val = x_train, y_train, x_val, y_val \n","  print([x.shape for x in [X_train, y_train, X_val, y_val]])\n","  sess.run(tf.initialize_all_variables())\n","  get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=20)\n","  for epoch in range(10):\n","    #Loop for each epoch\n","    total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int64)\n","    total_loss = 0\n","    total_acc = 0\n","    for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","        # Loop for each mini-batch\n","        sess.run(train_optimizer, feed_dict={X: mini_batch_x, Y: mini_batch_y})            \n","        loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","        total_loss += loss\n","    total_loss /= n_samples\n","\n","    val_loss, acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n","    print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}\".format(epoch, total_loss, val_loss, acc))\n","  # test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n","  # print(\"test_acc : {:.3f}\".format(test_acc))\n","\n","# 15680,10"]},{"cell_type":"markdown","metadata":{},"source":["-------------------------------------------------------------------------------------------"]},{"cell_type":"markdown","metadata":{},"source":["This is the end of my assignment. Thank you for reading!"]}],"metadata":{"interpreter":{"hash":"26e78bd553b95be0b58407d4e230199be8d6925e41b449e18e4d85b81bf49eae"},"kernelspec":{"display_name":"Python 3.6.8 64-bit ('3.6.8': pyenv)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
